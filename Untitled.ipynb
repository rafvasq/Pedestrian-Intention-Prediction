{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "dataPath = '../PedestrianData/IntentionData'\n",
    "finalPath = '../PedestrianData/final.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(dataPath)\n",
    "final = []\n",
    "for i in range(len(files)):\n",
    "    file = dataPath + \"/\" + files[i]\n",
    "    \n",
    "    # Reading trial csv to headers\n",
    "    df = pd.read_csv(file, sep=\",\", header=None, \n",
    "                 names=[\"Time\", \n",
    "                        \"Pos_x\", \"Pos_y\", \"Pos_z\", \n",
    "                        \"Gaz_x\", \"Gaz_y\", \"Gaz_z\", \n",
    "                        \"Vel_x\", \"Vel_z\",\n",
    "                        \"Acc_x\", \"Acc_z\",\n",
    "                        \"Vel_Mag\", \"Acc_Mag\",\n",
    "                        \"Vel_Ang\", \"Acc_Ang\", \"Gaz_Ang\",\n",
    "                        \"Vel_Bin\", \"Acc_Bin\", \"Gaz_Bin\", \"Chg_Bin\"          \n",
    "                       ])\n",
    "    \n",
    "    \n",
    "    final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = final[0]\n",
    "dataset.drop(\"Time\", axis = 1, inplace = True)\n",
    "dataset.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "values = dataset.values\n",
    "values = values.astype('float32')\n",
    "# specify columns to plot\n",
    "groups = [0, 1, 2, 3, 5, 6, 7]\n",
    "i = 1\n",
    "# plot each column\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i)\n",
    "    pyplot.plot(values[:, group])\n",
    "    pyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var2(t-5)</th>\n",
       "      <th>var3(t-5)</th>\n",
       "      <th>var4(t-5)</th>\n",
       "      <th>var5(t-5)</th>\n",
       "      <th>var6(t-5)</th>\n",
       "      <th>var7(t-5)</th>\n",
       "      <th>var8(t-5)</th>\n",
       "      <th>var9(t-5)</th>\n",
       "      <th>var10(t-5)</th>\n",
       "      <th>var11(t-5)</th>\n",
       "      <th>var12(t-5)</th>\n",
       "      <th>var13(t-5)</th>\n",
       "      <th>var14(t-5)</th>\n",
       "      <th>var15(t-5)</th>\n",
       "      <th>var16(t-5)</th>\n",
       "      <th>var17(t-5)</th>\n",
       "      <th>var18(t-5)</th>\n",
       "      <th>var19(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var2(t-4)</th>\n",
       "      <th>var3(t-4)</th>\n",
       "      <th>var4(t-4)</th>\n",
       "      <th>var5(t-4)</th>\n",
       "      <th>var6(t-4)</th>\n",
       "      <th>var7(t-4)</th>\n",
       "      <th>var8(t-4)</th>\n",
       "      <th>var9(t-4)</th>\n",
       "      <th>var10(t-4)</th>\n",
       "      <th>var11(t-4)</th>\n",
       "      <th>var12(t-4)</th>\n",
       "      <th>var13(t-4)</th>\n",
       "      <th>var14(t-4)</th>\n",
       "      <th>var15(t-4)</th>\n",
       "      <th>var16(t-4)</th>\n",
       "      <th>var17(t-4)</th>\n",
       "      <th>var18(t-4)</th>\n",
       "      <th>var19(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var6(t-3)</th>\n",
       "      <th>var7(t-3)</th>\n",
       "      <th>var8(t-3)</th>\n",
       "      <th>var9(t-3)</th>\n",
       "      <th>var10(t-3)</th>\n",
       "      <th>var11(t-3)</th>\n",
       "      <th>var12(t-3)</th>\n",
       "      <th>var13(t-3)</th>\n",
       "      <th>var14(t-3)</th>\n",
       "      <th>var15(t-3)</th>\n",
       "      <th>var16(t-3)</th>\n",
       "      <th>var17(t-3)</th>\n",
       "      <th>var18(t-3)</th>\n",
       "      <th>var19(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var6(t-2)</th>\n",
       "      <th>var7(t-2)</th>\n",
       "      <th>var8(t-2)</th>\n",
       "      <th>var9(t-2)</th>\n",
       "      <th>var10(t-2)</th>\n",
       "      <th>var11(t-2)</th>\n",
       "      <th>var12(t-2)</th>\n",
       "      <th>var13(t-2)</th>\n",
       "      <th>var14(t-2)</th>\n",
       "      <th>var15(t-2)</th>\n",
       "      <th>var16(t-2)</th>\n",
       "      <th>var17(t-2)</th>\n",
       "      <th>var18(t-2)</th>\n",
       "      <th>var19(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "      <th>var11(t-1)</th>\n",
       "      <th>var12(t-1)</th>\n",
       "      <th>var13(t-1)</th>\n",
       "      <th>var14(t-1)</th>\n",
       "      <th>var15(t-1)</th>\n",
       "      <th>var16(t-1)</th>\n",
       "      <th>var17(t-1)</th>\n",
       "      <th>var18(t-1)</th>\n",
       "      <th>var19(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "      <th>var9(t)</th>\n",
       "      <th>var10(t)</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "      <th>var13(t)</th>\n",
       "      <th>var14(t)</th>\n",
       "      <th>var15(t)</th>\n",
       "      <th>var16(t)</th>\n",
       "      <th>var17(t)</th>\n",
       "      <th>var18(t)</th>\n",
       "      <th>var19(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.130096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.945389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.904137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.174638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.904137</td>\n",
       "      <td>8.174638</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.126746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.126746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.889563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.913230</td>\n",
       "      <td>0.889563</td>\n",
       "      <td>7.913230</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>233.130096</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.945389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.904137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.174638</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.904137</td>\n",
       "      <td>8.174638</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.126746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.126746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.889563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.913230</td>\n",
       "      <td>0.889563</td>\n",
       "      <td>7.913230</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>233.130096</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.904137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.174638</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.904137</td>\n",
       "      <td>8.174638</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.126746</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.126746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.889563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.913230</td>\n",
       "      <td>0.889563</td>\n",
       "      <td>7.913230</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>233.130096</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212.005386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.126746</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.126746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.889563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.913230</td>\n",
       "      <td>0.889563</td>\n",
       "      <td>7.913230</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>233.130096</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212.005386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>198.434952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.037506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.889563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.91323</td>\n",
       "      <td>0.889563</td>\n",
       "      <td>7.913230</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>233.130096</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212.005386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>198.434952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>186.340195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.889563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.91323</td>\n",
       "      <td>0.889563</td>\n",
       "      <td>7.913230</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>233.130096</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.10122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.005386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>198.434952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>186.340195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.10122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.101220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.005386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.434952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>186.340195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.996195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.924036</td>\n",
       "      <td>1.408832</td>\n",
       "      <td>9.924036</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>171.869904</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.005386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.434952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.340195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.996195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.924036</td>\n",
       "      <td>1.408832</td>\n",
       "      <td>9.924036</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>171.869904</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.899208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.085747</td>\n",
       "      <td>8.957859</td>\n",
       "      <td>0.899208</td>\n",
       "      <td>12.067416</td>\n",
       "      <td>90.0</td>\n",
       "      <td>42.070759</td>\n",
       "      <td>161.565048</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.434952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.340195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.996195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.924036</td>\n",
       "      <td>1.408832</td>\n",
       "      <td>9.924036</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>171.869904</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.899208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.085747</td>\n",
       "      <td>8.957859</td>\n",
       "      <td>0.899208</td>\n",
       "      <td>12.067416</td>\n",
       "      <td>90.0</td>\n",
       "      <td>42.070759</td>\n",
       "      <td>161.565048</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.104841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.104841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>158.198593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.340195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.8</td>\n",
       "      <td>653.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.899994</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.996195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.924036</td>\n",
       "      <td>1.408832</td>\n",
       "      <td>9.924036</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>171.869904</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.899208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.085747</td>\n",
       "      <td>8.957859</td>\n",
       "      <td>0.899208</td>\n",
       "      <td>12.067416</td>\n",
       "      <td>90.0</td>\n",
       "      <td>42.070759</td>\n",
       "      <td>161.565048</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.104841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.104841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>158.198593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>653.799988</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158.198593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-5)  var2(t-5)   var3(t-5)  var4(t-5)  var5(t-5)  var6(t-5)  \\\n",
       "5   290.000000        1.8  654.000000       -0.8       -0.2       -0.6   \n",
       "6   290.000000        1.8  654.000000       -0.9       -0.2       -0.5   \n",
       "7   289.899994        1.8  654.000000       -0.9       -0.1       -0.4   \n",
       "8   289.899994        1.8  654.000000       -0.9       -0.2       -0.4   \n",
       "9   289.899994        1.8  654.000000       -0.9       -0.2       -0.4   \n",
       "10  289.899994        1.8  653.900024       -0.8       -0.2       -0.6   \n",
       "11  289.899994        1.8  653.900024       -0.7       -0.2       -0.7   \n",
       "12  289.899994        1.8  653.900024       -0.5       -0.3       -0.8   \n",
       "13  289.899994        1.8  653.900024       -0.3       -0.3       -0.9   \n",
       "14  289.899994        1.8  653.900024       -0.1       -0.4       -0.9   \n",
       "\n",
       "    var7(t-5)  var8(t-5)  var9(t-5)  var10(t-5)  var11(t-5)  var12(t-5)  \\\n",
       "5    0.000000   0.000000   0.000000     0.00000    0.000000    0.000000   \n",
       "6    0.000000   0.000000   0.000000     0.00000    0.000000    0.000000   \n",
       "7   -0.904137   0.000000  -8.174638     0.00000    0.904137    8.174638   \n",
       "8    0.000000   0.000000   8.126746     0.00000    0.000000    8.126746   \n",
       "9    0.000000   0.000000   0.000000     0.00000    0.000000    0.000000   \n",
       "10   0.000000  -0.889563   0.000000    -7.91323    0.889563    7.913230   \n",
       "11   0.000000   0.000000   0.000000     8.10122    0.000000    8.101220   \n",
       "12   0.000000   0.000000   0.000000     0.00000    0.000000    0.000000   \n",
       "13   0.000000   0.000000   0.000000     0.00000    0.000000    0.000000   \n",
       "14   0.000000   0.000000   0.000000     0.00000    0.000000    0.000000   \n",
       "\n",
       "    var13(t-5)  var14(t-5)  var15(t-5)  var16(t-5)  var17(t-5)  var18(t-5)  \\\n",
       "5          0.0         0.0  233.130096         0.0         0.0         6.0   \n",
       "6          0.0         0.0  240.945389         0.0         0.0         6.0   \n",
       "7        270.0       270.0  246.037506         7.0         7.0         6.0   \n",
       "8          0.0        90.0  246.037506         0.0         3.0         6.0   \n",
       "9          0.0         0.0  246.037506         0.0         0.0         6.0   \n",
       "10       180.0       180.0  233.130096         5.0         5.0         6.0   \n",
       "11         0.0         0.0  225.000000         0.0         1.0         6.0   \n",
       "12         0.0         0.0  212.005386         0.0         0.0         5.0   \n",
       "13         0.0         0.0  198.434952         0.0         0.0         5.0   \n",
       "14         0.0         0.0  186.340195         0.0         0.0         5.0   \n",
       "\n",
       "    var19(t-5)   var1(t-4)  var2(t-4)   var3(t-4)  var4(t-4)  var5(t-4)  \\\n",
       "5          6.0  290.000000        1.8  654.000000       -0.9       -0.2   \n",
       "6          4.0  289.899994        1.8  654.000000       -0.9       -0.1   \n",
       "7          4.0  289.899994        1.8  654.000000       -0.9       -0.2   \n",
       "8          3.0  289.899994        1.8  654.000000       -0.9       -0.2   \n",
       "9          3.0  289.899994        1.8  653.900024       -0.8       -0.2   \n",
       "10         2.0  289.899994        1.8  653.900024       -0.7       -0.2   \n",
       "11         3.0  289.899994        1.8  653.900024       -0.5       -0.3   \n",
       "12         2.0  289.899994        1.8  653.900024       -0.3       -0.3   \n",
       "13         2.0  289.899994        1.8  653.900024       -0.1       -0.4   \n",
       "14         2.0  289.899994        1.8  653.900024        0.0       -0.5   \n",
       "\n",
       "    var6(t-4)  var7(t-4)  var8(t-4)  var9(t-4)  var10(t-4)  var11(t-4)  \\\n",
       "5        -0.5   0.000000   0.000000   0.000000     0.00000    0.000000   \n",
       "6        -0.4  -0.904137   0.000000  -8.174638     0.00000    0.904137   \n",
       "7        -0.4   0.000000   0.000000   8.126746     0.00000    0.000000   \n",
       "8        -0.4   0.000000   0.000000   0.000000     0.00000    0.000000   \n",
       "9        -0.6   0.000000  -0.889563   0.000000    -7.91323    0.889563   \n",
       "10       -0.7   0.000000   0.000000   0.000000     8.10122    0.000000   \n",
       "11       -0.8   0.000000   0.000000   0.000000     0.00000    0.000000   \n",
       "12       -0.9   0.000000   0.000000   0.000000     0.00000    0.000000   \n",
       "13       -0.9   0.000000   0.000000   0.000000     0.00000    0.000000   \n",
       "14       -0.9   0.000000   0.000000   0.000000     0.00000    0.000000   \n",
       "\n",
       "    var12(t-4)  var13(t-4)  var14(t-4)  var15(t-4)  var16(t-4)  var17(t-4)  \\\n",
       "5     0.000000         0.0         0.0  240.945389         0.0         0.0   \n",
       "6     8.174638       270.0       270.0  246.037506         7.0         7.0   \n",
       "7     8.126746         0.0        90.0  246.037506         0.0         3.0   \n",
       "8     0.000000         0.0         0.0  246.037506         0.0         0.0   \n",
       "9     7.913230       180.0       180.0  233.130096         5.0         5.0   \n",
       "10    8.101220         0.0         0.0  225.000000         0.0         1.0   \n",
       "11    0.000000         0.0         0.0  212.005386         0.0         0.0   \n",
       "12    0.000000         0.0         0.0  198.434952         0.0         0.0   \n",
       "13    0.000000         0.0         0.0  186.340195         0.0         0.0   \n",
       "14    0.000000         0.0         0.0  180.000000         0.0         0.0   \n",
       "\n",
       "    var18(t-4)  var19(t-4)   var1(t-3)  var2(t-3)   var3(t-3)  var4(t-3)  \\\n",
       "5          6.0         4.0  289.899994        1.8  654.000000       -0.9   \n",
       "6          6.0         4.0  289.899994        1.8  654.000000       -0.9   \n",
       "7          6.0         3.0  289.899994        1.8  654.000000       -0.9   \n",
       "8          6.0         3.0  289.899994        1.8  653.900024       -0.8   \n",
       "9          6.0         2.0  289.899994        1.8  653.900024       -0.7   \n",
       "10         6.0         3.0  289.899994        1.8  653.900024       -0.5   \n",
       "11         5.0         2.0  289.899994        1.8  653.900024       -0.3   \n",
       "12         5.0         2.0  289.899994        1.8  653.900024       -0.1   \n",
       "13         5.0         2.0  289.899994        1.8  653.900024        0.0   \n",
       "14         5.0         3.0  289.899994        1.7  653.799988        0.1   \n",
       "\n",
       "    var5(t-3)  var6(t-3)  var7(t-3)  var8(t-3)  var9(t-3)  var10(t-3)  \\\n",
       "5        -0.1       -0.4  -0.904137   0.000000  -8.174638    0.000000   \n",
       "6        -0.2       -0.4   0.000000   0.000000   8.126746    0.000000   \n",
       "7        -0.2       -0.4   0.000000   0.000000   0.000000    0.000000   \n",
       "8        -0.2       -0.6   0.000000  -0.889563   0.000000   -7.913230   \n",
       "9        -0.2       -0.7   0.000000   0.000000   0.000000    8.101220   \n",
       "10       -0.3       -0.8   0.000000   0.000000   0.000000    0.000000   \n",
       "11       -0.3       -0.9   0.000000   0.000000   0.000000    0.000000   \n",
       "12       -0.4       -0.9   0.000000   0.000000   0.000000    0.000000   \n",
       "13       -0.5       -0.9   0.000000   0.000000   0.000000    0.000000   \n",
       "14       -0.7       -0.7   0.000000  -0.996195   0.000000   -9.924036   \n",
       "\n",
       "    var11(t-3)  var12(t-3)  var13(t-3)  var14(t-3)  var15(t-3)  var16(t-3)  \\\n",
       "5     0.904137    8.174638       270.0       270.0  246.037506         7.0   \n",
       "6     0.000000    8.126746         0.0        90.0  246.037506         0.0   \n",
       "7     0.000000    0.000000         0.0         0.0  246.037506         0.0   \n",
       "8     0.889563    7.913230       180.0       180.0  233.130096         5.0   \n",
       "9     0.000000    8.101220         0.0         0.0  225.000000         0.0   \n",
       "10    0.000000    0.000000         0.0         0.0  212.005386         0.0   \n",
       "11    0.000000    0.000000         0.0         0.0  198.434952         0.0   \n",
       "12    0.000000    0.000000         0.0         0.0  186.340195         0.0   \n",
       "13    0.000000    0.000000         0.0         0.0  180.000000         0.0   \n",
       "14    1.408832    9.924036       180.0       180.0  171.869904         5.0   \n",
       "\n",
       "    var17(t-3)  var18(t-3)  var19(t-3)   var1(t-2)  var2(t-2)   var3(t-2)  \\\n",
       "5          7.0         6.0         4.0  289.899994        1.8  654.000000   \n",
       "6          3.0         6.0         3.0  289.899994        1.8  654.000000   \n",
       "7          0.0         6.0         3.0  289.899994        1.8  653.900024   \n",
       "8          5.0         6.0         2.0  289.899994        1.8  653.900024   \n",
       "9          1.0         6.0         3.0  289.899994        1.8  653.900024   \n",
       "10         0.0         5.0         2.0  289.899994        1.8  653.900024   \n",
       "11         0.0         5.0         2.0  289.899994        1.8  653.900024   \n",
       "12         0.0         5.0         2.0  289.899994        1.8  653.900024   \n",
       "13         0.0         5.0         3.0  289.899994        1.7  653.799988   \n",
       "14         5.0         4.0         3.0  290.000000        1.7  653.799988   \n",
       "\n",
       "    var4(t-2)  var5(t-2)  var6(t-2)  var7(t-2)  var8(t-2)  var9(t-2)  \\\n",
       "5        -0.9       -0.2       -0.4   0.000000   0.000000   8.126746   \n",
       "6        -0.9       -0.2       -0.4   0.000000   0.000000   0.000000   \n",
       "7        -0.8       -0.2       -0.6   0.000000  -0.889563   0.000000   \n",
       "8        -0.7       -0.2       -0.7   0.000000   0.000000   0.000000   \n",
       "9        -0.5       -0.3       -0.8   0.000000   0.000000   0.000000   \n",
       "10       -0.3       -0.3       -0.9   0.000000   0.000000   0.000000   \n",
       "11       -0.1       -0.4       -0.9   0.000000   0.000000   0.000000   \n",
       "12        0.0       -0.5       -0.9   0.000000   0.000000   0.000000   \n",
       "13        0.1       -0.7       -0.7   0.000000  -0.996195   0.000000   \n",
       "14        0.2       -0.8       -0.6   0.899208   0.000000   8.085747   \n",
       "\n",
       "    var10(t-2)  var11(t-2)  var12(t-2)  var13(t-2)  var14(t-2)  var15(t-2)  \\\n",
       "5     0.000000    0.000000    8.126746         0.0   90.000000  246.037506   \n",
       "6     0.000000    0.000000    0.000000         0.0    0.000000  246.037506   \n",
       "7    -7.913230    0.889563    7.913230       180.0  180.000000  233.130096   \n",
       "8     8.101220    0.000000    8.101220         0.0    0.000000  225.000000   \n",
       "9     0.000000    0.000000    0.000000         0.0    0.000000  212.005386   \n",
       "10    0.000000    0.000000    0.000000         0.0    0.000000  198.434952   \n",
       "11    0.000000    0.000000    0.000000         0.0    0.000000  186.340195   \n",
       "12    0.000000    0.000000    0.000000         0.0    0.000000  180.000000   \n",
       "13   -9.924036    1.408832    9.924036       180.0  180.000000  171.869904   \n",
       "14    8.957859    0.899208   12.067416        90.0   42.070759  161.565048   \n",
       "\n",
       "    var16(t-2)  var17(t-2)  var18(t-2)  var19(t-2)   var1(t-1)  var2(t-1)  \\\n",
       "5          0.0         3.0         6.0         3.0  289.899994        1.8   \n",
       "6          0.0         0.0         6.0         3.0  289.899994        1.8   \n",
       "7          5.0         5.0         6.0         2.0  289.899994        1.8   \n",
       "8          0.0         1.0         6.0         3.0  289.899994        1.8   \n",
       "9          0.0         0.0         5.0         2.0  289.899994        1.8   \n",
       "10         0.0         0.0         5.0         2.0  289.899994        1.8   \n",
       "11         0.0         0.0         5.0         2.0  289.899994        1.8   \n",
       "12         0.0         0.0         5.0         3.0  289.899994        1.7   \n",
       "13         5.0         5.0         4.0         3.0  290.000000        1.7   \n",
       "14         3.0         1.0         4.0         2.0  290.000000        1.7   \n",
       "\n",
       "     var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)  \\\n",
       "5   654.000000       -0.9       -0.2       -0.4   0.000000   0.000000   \n",
       "6   653.900024       -0.8       -0.2       -0.6   0.000000  -0.889563   \n",
       "7   653.900024       -0.7       -0.2       -0.7   0.000000   0.000000   \n",
       "8   653.900024       -0.5       -0.3       -0.8   0.000000   0.000000   \n",
       "9   653.900024       -0.3       -0.3       -0.9   0.000000   0.000000   \n",
       "10  653.900024       -0.1       -0.4       -0.9   0.000000   0.000000   \n",
       "11  653.900024        0.0       -0.5       -0.9   0.000000   0.000000   \n",
       "12  653.799988        0.1       -0.7       -0.7   0.000000  -0.996195   \n",
       "13  653.799988        0.2       -0.8       -0.6   0.899208   0.000000   \n",
       "14  653.799988        0.2       -0.8       -0.5   0.000000   0.000000   \n",
       "\n",
       "    var9(t-1)  var10(t-1)  var11(t-1)  var12(t-1)  var13(t-1)  var14(t-1)  \\\n",
       "5    0.000000    0.000000    0.000000    0.000000         0.0    0.000000   \n",
       "6    0.000000   -7.913230    0.889563    7.913230       180.0  180.000000   \n",
       "7    0.000000    8.101220    0.000000    8.101220         0.0    0.000000   \n",
       "8    0.000000    0.000000    0.000000    0.000000         0.0    0.000000   \n",
       "9    0.000000    0.000000    0.000000    0.000000         0.0    0.000000   \n",
       "10   0.000000    0.000000    0.000000    0.000000         0.0    0.000000   \n",
       "11   0.000000    0.000000    0.000000    0.000000         0.0    0.000000   \n",
       "12   0.000000   -9.924036    1.408832    9.924036       180.0  180.000000   \n",
       "13   8.085747    8.957859    0.899208   12.067416        90.0   42.070759   \n",
       "14  -8.104841    0.000000    0.000000    8.104841         0.0  270.000000   \n",
       "\n",
       "    var15(t-1)  var16(t-1)  var17(t-1)  var18(t-1)  var19(t-1)     var1(t)  \\\n",
       "5   246.037506         0.0         0.0         6.0         3.0  289.899994   \n",
       "6   233.130096         5.0         5.0         6.0         2.0  289.899994   \n",
       "7   225.000000         0.0         1.0         6.0         3.0  289.899994   \n",
       "8   212.005386         0.0         0.0         5.0         2.0  289.899994   \n",
       "9   198.434952         0.0         0.0         5.0         2.0  289.899994   \n",
       "10  186.340195         0.0         0.0         5.0         2.0  289.899994   \n",
       "11  180.000000         0.0         0.0         5.0         3.0  289.899994   \n",
       "12  171.869904         5.0         5.0         4.0         3.0  290.000000   \n",
       "13  161.565048         3.0         1.0         4.0         2.0  290.000000   \n",
       "14  158.198593         0.0         7.0         4.0         3.0  290.000000   \n",
       "\n",
       "    var2(t)     var3(t)  var4(t)  var5(t)  var6(t)   var7(t)   var8(t)  \\\n",
       "5       1.8  653.900024     -0.8     -0.2     -0.6  0.000000 -0.889563   \n",
       "6       1.8  653.900024     -0.7     -0.2     -0.7  0.000000  0.000000   \n",
       "7       1.8  653.900024     -0.5     -0.3     -0.8  0.000000  0.000000   \n",
       "8       1.8  653.900024     -0.3     -0.3     -0.9  0.000000  0.000000   \n",
       "9       1.8  653.900024     -0.1     -0.4     -0.9  0.000000  0.000000   \n",
       "10      1.8  653.900024      0.0     -0.5     -0.9  0.000000  0.000000   \n",
       "11      1.7  653.799988      0.1     -0.7     -0.7  0.000000 -0.996195   \n",
       "12      1.7  653.799988      0.2     -0.8     -0.6  0.899208  0.000000   \n",
       "13      1.7  653.799988      0.2     -0.8     -0.5  0.000000  0.000000   \n",
       "14      1.7  653.799988      0.2     -0.8     -0.5  0.000000  0.000000   \n",
       "\n",
       "     var9(t)  var10(t)  var11(t)   var12(t)  var13(t)    var14(t)    var15(t)  \\\n",
       "5   0.000000 -7.913230  0.889563   7.913230     180.0  180.000000  233.130096   \n",
       "6   0.000000  8.101220  0.000000   8.101220       0.0    0.000000  225.000000   \n",
       "7   0.000000  0.000000  0.000000   0.000000       0.0    0.000000  212.005386   \n",
       "8   0.000000  0.000000  0.000000   0.000000       0.0    0.000000  198.434952   \n",
       "9   0.000000  0.000000  0.000000   0.000000       0.0    0.000000  186.340195   \n",
       "10  0.000000  0.000000  0.000000   0.000000       0.0    0.000000  180.000000   \n",
       "11  0.000000 -9.924036  1.408832   9.924036     180.0  180.000000  171.869904   \n",
       "12  8.085747  8.957859  0.899208  12.067416      90.0   42.070759  161.565048   \n",
       "13 -8.104841  0.000000  0.000000   8.104841       0.0  270.000000  158.198593   \n",
       "14  0.000000  0.000000  0.000000   0.000000       0.0    0.000000  158.198593   \n",
       "\n",
       "    var16(t)  var17(t)  var18(t)  var19(t)  \n",
       "5        5.0       5.0       6.0       2.0  \n",
       "6        0.0       1.0       6.0       3.0  \n",
       "7        0.0       0.0       5.0       2.0  \n",
       "8        0.0       0.0       5.0       2.0  \n",
       "9        0.0       0.0       5.0       2.0  \n",
       "10       0.0       0.0       5.0       3.0  \n",
       "11       5.0       5.0       4.0       3.0  \n",
       "12       3.0       1.0       4.0       2.0  \n",
       "13       0.0       7.0       4.0       3.0  \n",
       "14       0.0       0.0       4.0       3.0  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "reframed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 85) 100 (100,)\n",
      "(100, 5, 17) (100,) (127, 5, 17) (127,)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 5\n",
    "n_features = 17\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_timesteps_train = 100\n",
    "train = values[:n_timesteps_train, :]\n",
    "test = values[n_timesteps_train:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_steps * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_steps, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_steps, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 127 samples\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 651.4157 - val_loss: 646.6624\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 645.8766 - val_loss: 639.6172\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 636.6653 - val_loss: 628.9277\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 623.8548 - val_loss: 614.8193\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 607.4378 - val_loss: 597.1959\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 587.4230 - val_loss: 576.1230\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 563.8850 - val_loss: 551.6613\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 536.9145 - val_loss: 523.8033\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 506.4474 - val_loss: 492.5804\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 472.7444 - val_loss: 458.4456\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 435.9611 - val_loss: 421.2811\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 396.1276 - val_loss: 381.1850\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 353.3339 - val_loss: 338.2825\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 307.3143 - val_loss: 291.3476\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 258.3652 - val_loss: 242.7703\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 206.9957 - val_loss: 191.5892\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 152.9754 - val_loss: 137.8689\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 96.3709 - val_loss: 81.6737\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 37.2448 - val_loss: 24.1608\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.5969 - val_loss: 23.0457\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.2237 - val_loss: 23.0612\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.3365 - val_loss: 22.8472\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.1931 - val_loss: 22.7787\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.1634 - val_loss: 22.6196\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.1009 - val_loss: 22.5156\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.0730 - val_loss: 22.4067\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.0998 - val_loss: 22.3230\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.1444 - val_loss: 22.1863\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.9994 - val_loss: 22.0819\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.0297 - val_loss: 22.0645\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.0771 - val_loss: 21.9248\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.9315 - val_loss: 21.8344\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.9345 - val_loss: 21.8251\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.0307 - val_loss: 21.5662\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.9216 - val_loss: 21.4666\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.8909 - val_loss: 21.4576\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.9617 - val_loss: 21.2486\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.8298 - val_loss: 21.1794\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.0954 - val_loss: 21.2527\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.8970 - val_loss: 21.0471\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.7666 - val_loss: 21.0805\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.7588 - val_loss: 21.0637\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.7508 - val_loss: 20.8719\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.6899 - val_loss: 20.8213\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.7156 - val_loss: 20.7287\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.7740 - val_loss: 20.4364\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 3.6826 - val_loss: 20.3875\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.6209 - val_loss: 20.3366\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.6546 - val_loss: 20.2500\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.6379 - val_loss: 20.1696\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.6614 - val_loss: 20.0612\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.6114 - val_loss: 19.9630\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.5621 - val_loss: 19.8894\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.4979 - val_loss: 19.8106\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.4725 - val_loss: 19.7676\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.4697 - val_loss: 19.6903\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.4459 - val_loss: 19.6137\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.4304 - val_loss: 19.5679\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.3953 - val_loss: 19.5018\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.3667 - val_loss: 19.4310\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.3449 - val_loss: 19.3906\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.3606 - val_loss: 19.3286\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.3008 - val_loss: 19.2990\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.3196 - val_loss: 19.2317\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.2419 - val_loss: 19.1872\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.2510 - val_loss: 19.1516\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.2352 - val_loss: 19.1007\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.2010 - val_loss: 19.0673\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.1739 - val_loss: 18.9993\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.1904 - val_loss: 18.9561\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.1233 - val_loss: 18.9027\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.1030 - val_loss: 18.8781\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.0994 - val_loss: 18.8519\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.0905 - val_loss: 18.7897\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.0978 - val_loss: 18.7713\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.0222 - val_loss: 18.7232\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9902 - val_loss: 18.6913\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9806 - val_loss: 18.6615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9693 - val_loss: 18.6383\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9722 - val_loss: 18.5919\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9671 - val_loss: 18.5654\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.0077 - val_loss: 18.5241\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8962 - val_loss: 18.4962\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9141 - val_loss: 18.4704\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9105 - val_loss: 18.4256\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8861 - val_loss: 18.3912\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9014 - val_loss: 18.3782\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8735 - val_loss: 18.3107\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8455 - val_loss: 18.2860\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8615 - val_loss: 18.2404\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8241 - val_loss: 18.2124\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8203 - val_loss: 18.1730\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.7953 - val_loss: 18.1578\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.7808 - val_loss: 18.1086\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.7793 - val_loss: 18.0754\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.7835 - val_loss: 18.0639\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8725 - val_loss: 18.0164\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.7701 - val_loss: 17.9730\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.7285 - val_loss: 17.9423\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 2.7745 - val_loss: 17.9309\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.7574 - val_loss: 17.8738\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6841 - val_loss: 17.8377\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6909 - val_loss: 17.8000\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6559 - val_loss: 17.7744\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6608 - val_loss: 17.7413\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6278 - val_loss: 17.7049\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6424 - val_loss: 17.6727\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6035 - val_loss: 17.6338\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6785 - val_loss: 17.6084\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6427 - val_loss: 17.5699\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5886 - val_loss: 17.5372\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6096 - val_loss: 17.5239\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5927 - val_loss: 17.4678\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5760 - val_loss: 17.4430\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5528 - val_loss: 17.4143\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6043 - val_loss: 17.3717\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5287 - val_loss: 17.3425\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5219 - val_loss: 17.3155\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4973 - val_loss: 17.2849\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4834 - val_loss: 17.2502\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4525 - val_loss: 17.2145\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4659 - val_loss: 17.1902\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4502 - val_loss: 17.1624\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4465 - val_loss: 17.1283\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4505 - val_loss: 17.0967\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4274 - val_loss: 17.0733\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4239 - val_loss: 17.0432\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3654 - val_loss: 17.0120\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3912 - val_loss: 16.9849\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3889 - val_loss: 16.9629\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3599 - val_loss: 16.9349\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 2.3755 - val_loss: 16.9201\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3548 - val_loss: 16.8749\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3420 - val_loss: 16.8516\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3131 - val_loss: 16.8235\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2713 - val_loss: 16.7982\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.3547 - val_loss: 16.7819\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2794 - val_loss: 16.7432\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2678 - val_loss: 16.7124\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2309 - val_loss: 16.6867\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2396 - val_loss: 16.6574\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2117 - val_loss: 16.6290\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2073 - val_loss: 16.6035\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1865 - val_loss: 16.5742\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1757 - val_loss: 16.5436\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1501 - val_loss: 16.5303\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1563 - val_loss: 16.4911\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1514 - val_loss: 16.4767\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2464 - val_loss: 16.4410\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1281 - val_loss: 16.4196\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1220 - val_loss: 16.3798\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1030 - val_loss: 16.3604\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1655 - val_loss: 16.3352\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 2.0744 - val_loss: 16.3114\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1071 - val_loss: 16.2742\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0729 - val_loss: 16.2465\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0593 - val_loss: 16.2147\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1066 - val_loss: 16.1998\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0687 - val_loss: 16.1608\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0520 - val_loss: 16.1395\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0674 - val_loss: 16.1175\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9921 - val_loss: 16.0798\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9761 - val_loss: 16.0552\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0815 - val_loss: 16.0293\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9544 - val_loss: 16.0163\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0640 - val_loss: 15.9969\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9734 - val_loss: 15.9670\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9315 - val_loss: 15.9313\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9276 - val_loss: 15.8998\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8704 - val_loss: 15.8769\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8770 - val_loss: 15.8567\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8609 - val_loss: 15.8304\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8662 - val_loss: 15.8037\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8245 - val_loss: 15.7805\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8396 - val_loss: 15.7557\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8106 - val_loss: 15.7322\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7950 - val_loss: 15.7226\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7858 - val_loss: 15.6915\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8933 - val_loss: 15.6630\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7668 - val_loss: 15.6378\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7836 - val_loss: 15.6191\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7695 - val_loss: 15.5929\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8169 - val_loss: 15.5736\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 15.5487\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7699 - val_loss: 15.5239\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7164 - val_loss: 15.5007\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6767 - val_loss: 15.4780\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7164 - val_loss: 15.4557\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6738 - val_loss: 15.4335\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6839 - val_loss: 15.4108\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6671 - val_loss: 15.3890\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6795 - val_loss: 15.3656\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6563 - val_loss: 15.3470\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6639 - val_loss: 15.3200\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6101 - val_loss: 15.2968\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5773 - val_loss: 15.2739\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6058 - val_loss: 15.2525\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5758 - val_loss: 15.2329\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5800 - val_loss: 15.2359\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5435 - val_loss: 15.1957\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5782 - val_loss: 15.2325\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6519 - val_loss: 15.3258\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4977 - val_loss: 15.1555\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4882 - val_loss: 15.1099\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4669 - val_loss: 15.0936\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5069 - val_loss: 15.0719\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4481 - val_loss: 15.0594\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4413 - val_loss: 15.0483\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4290 - val_loss: 15.0187\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4090 - val_loss: 15.0234\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4029 - val_loss: 14.9954\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4083 - val_loss: 14.9660\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4153 - val_loss: 14.9847\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3568 - val_loss: 14.9420\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4151 - val_loss: 14.9144\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3838 - val_loss: 14.8963\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3748 - val_loss: 14.9125\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3273 - val_loss: 14.8795\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3213 - val_loss: 14.8477\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4600 - val_loss: 14.8467\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2786 - val_loss: 14.8774\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3186 - val_loss: 14.8616\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2763 - val_loss: 14.8429\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2377 - val_loss: 14.8468\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2757 - val_loss: 14.8314\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2164 - val_loss: 14.8505\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2457 - val_loss: 14.8836\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2030 - val_loss: 14.8482\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1828 - val_loss: 14.9123\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1779 - val_loss: 14.8700\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1777 - val_loss: 14.8237\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1623 - val_loss: 14.9109\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1663 - val_loss: 14.8618\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1930 - val_loss: 14.9260\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1081 - val_loss: 14.9021\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1120 - val_loss: 14.8854\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1360 - val_loss: 14.9039\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1242 - val_loss: 14.9439\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0587 - val_loss: 14.9848\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0587 - val_loss: 14.9668\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0226 - val_loss: 14.9772\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0488 - val_loss: 14.9433\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0351 - val_loss: 14.9590\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0910 - val_loss: 15.0334\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0079 - val_loss: 14.9517\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0669 - val_loss: 15.0214\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0155 - val_loss: 15.1044\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.9713 - val_loss: 15.0125\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0311 - val_loss: 15.0987\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.9560 - val_loss: 15.0206\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0139 - val_loss: 15.1130\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.9710 - val_loss: 15.1365\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.9148 - val_loss: 15.0860\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.9468 - val_loss: 15.0947\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8814 - val_loss: 15.1355\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8793 - val_loss: 15.2222\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8671 - val_loss: 15.2485\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8557 - val_loss: 15.1579\n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8239 - val_loss: 15.2504\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8186 - val_loss: 15.2117\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8038 - val_loss: 15.2142\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8375 - val_loss: 15.2177\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7986 - val_loss: 15.2711\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7790 - val_loss: 15.2806\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8484 - val_loss: 15.2519\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8267 - val_loss: 15.2559\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7736 - val_loss: 15.2411\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8224 - val_loss: 15.2735\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7977 - val_loss: 15.3139\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7855 - val_loss: 15.2525\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7551 - val_loss: 15.2116\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7686 - val_loss: 15.2323\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7440 - val_loss: 15.2476\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8012 - val_loss: 15.3724\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7927 - val_loss: 15.2930\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8045 - val_loss: 15.1764\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7770 - val_loss: 15.2562\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8270 - val_loss: 15.1528\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7773 - val_loss: 15.2177\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7389 - val_loss: 15.3548\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7930 - val_loss: 15.3308\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7858 - val_loss: 15.1933\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7302 - val_loss: 15.3148\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7644 - val_loss: 15.1884\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7423 - val_loss: 15.2322\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.7806 - val_loss: 15.2509\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7430 - val_loss: 15.1927\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7242 - val_loss: 15.1913\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7296 - val_loss: 15.2724\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7133 - val_loss: 15.2141\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7282 - val_loss: 15.2368\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7677 - val_loss: 15.3205\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8392 - val_loss: 15.2334\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7464 - val_loss: 15.2845\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7420 - val_loss: 15.2165\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7111 - val_loss: 15.2279\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7171 - val_loss: 15.1744\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7228 - val_loss: 15.2253\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7161 - val_loss: 15.1495\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7023 - val_loss: 15.2016\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7079 - val_loss: 15.2019\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7411 - val_loss: 15.2382\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7646 - val_loss: 15.2058\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7612 - val_loss: 15.2208\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7387 - val_loss: 15.3047\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8102 - val_loss: 15.2205\n",
      "Epoch 307/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7174 - val_loss: 15.2723\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7130 - val_loss: 15.2048\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6821 - val_loss: 15.2167\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6881 - val_loss: 15.1635\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6828 - val_loss: 15.2023\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6987 - val_loss: 15.1928\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7055 - val_loss: 15.1737\n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6735 - val_loss: 15.1725\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6713 - val_loss: 15.2510\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7353 - val_loss: 15.2032\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6462 - val_loss: 15.1506\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6581 - val_loss: 15.1962\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7071 - val_loss: 15.2071\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7701 - val_loss: 15.1919\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6966 - val_loss: 15.1900\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6594 - val_loss: 15.3656\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6799 - val_loss: 15.2357\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6396 - val_loss: 15.2519\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6611 - val_loss: 15.1980\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6749 - val_loss: 15.2330\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.7548 - val_loss: 15.1845\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6334 - val_loss: 15.1674\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 15.1701\n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.7080 - val_loss: 15.1292\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6365 - val_loss: 15.1635\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6157 - val_loss: 15.1801\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6708 - val_loss: 15.2883\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6616 - val_loss: 15.1830\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6298 - val_loss: 15.3431\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6144 - val_loss: 15.1830\n",
      "Epoch 337/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5981 - val_loss: 15.1416\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6328 - val_loss: 15.1833\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6437 - val_loss: 15.1683\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6053 - val_loss: 15.2803\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6407 - val_loss: 15.1836\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6465 - val_loss: 15.1529\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6002 - val_loss: 15.1689\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5813 - val_loss: 15.1993\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6384 - val_loss: 15.2841\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 15.1765\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6114 - val_loss: 15.1894\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6073 - val_loss: 15.2030\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 15.1612\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5877 - val_loss: 15.1863\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 15.2522\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6164 - val_loss: 15.1759\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5890 - val_loss: 15.2323\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6239 - val_loss: 15.2165\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 15.2657\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5940 - val_loss: 15.1976\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5711 - val_loss: 15.1755\n",
      "Epoch 358/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5899 - val_loss: 15.2692\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6376 - val_loss: 15.1440\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5491 - val_loss: 15.1930\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5425 - val_loss: 15.1777\n",
      "Epoch 362/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5455 - val_loss: 15.1812\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5680 - val_loss: 15.1698\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5934 - val_loss: 15.2030\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6340 - val_loss: 15.1470\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5558 - val_loss: 15.1852\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5885 - val_loss: 15.1200\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6081 - val_loss: 15.2118\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5832 - val_loss: 15.1615\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5767 - val_loss: 15.1608\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5384 - val_loss: 15.2389\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5372 - val_loss: 15.2171\n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5437 - val_loss: 15.2519\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5435 - val_loss: 15.2346\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5426 - val_loss: 15.1909\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5564 - val_loss: 15.2641\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5477 - val_loss: 15.2206\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 15.1701\n",
      "Epoch 379/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5132 - val_loss: 15.1917\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5418 - val_loss: 15.2275\n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5443 - val_loss: 15.2008\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5551 - val_loss: 15.3170\n",
      "Epoch 383/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5430 - val_loss: 15.1859\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5479 - val_loss: 15.1857\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5137 - val_loss: 15.1995\n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4925 - val_loss: 15.2284\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4960 - val_loss: 15.1637\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4857 - val_loss: 15.2185\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5037 - val_loss: 15.2520\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5224 - val_loss: 15.1997\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4973 - val_loss: 15.2726\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5304 - val_loss: 15.2954\n",
      "Epoch 393/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5207 - val_loss: 15.1807\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4986 - val_loss: 15.2252\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5090 - val_loss: 15.3149\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5444 - val_loss: 15.2067\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4955 - val_loss: 15.2750\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5206 - val_loss: 15.2550\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4824 - val_loss: 15.3768\n",
      "Epoch 400/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5564 - val_loss: 15.2534\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4724 - val_loss: 15.1761\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4787 - val_loss: 15.1909\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4743 - val_loss: 15.2091\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5234 - val_loss: 15.1347\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4656 - val_loss: 15.2742\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4905 - val_loss: 15.3958\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5053 - val_loss: 15.3758\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.5473 - val_loss: 15.1535\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4983 - val_loss: 15.2502\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4824 - val_loss: 15.2268\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4503 - val_loss: 15.2103\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4852 - val_loss: 15.2803\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4984 - val_loss: 15.1853\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4677 - val_loss: 15.2274\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4706 - val_loss: 15.2405\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4414 - val_loss: 15.2151\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4395 - val_loss: 15.2356\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4817 - val_loss: 15.3259\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4765 - val_loss: 15.3024\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4734 - val_loss: 15.2246\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4359 - val_loss: 15.2134\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4622 - val_loss: 15.2273\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4861 - val_loss: 15.3243\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4821 - val_loss: 15.3084\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4486 - val_loss: 15.2979\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4573 - val_loss: 15.3550\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4432 - val_loss: 15.2443\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4142 - val_loss: 15.2639\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4093 - val_loss: 15.2603\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4238 - val_loss: 15.2357\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4156 - val_loss: 15.2954\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4288 - val_loss: 15.3118\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4277 - val_loss: 15.2563\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3906 - val_loss: 15.2689\n",
      "Epoch 435/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3961 - val_loss: 15.2537\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4006 - val_loss: 15.2712\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4311 - val_loss: 15.2851\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3679 - val_loss: 15.2729\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4117 - val_loss: 15.2857\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4406 - val_loss: 15.3176\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4187 - val_loss: 15.3592\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4135 - val_loss: 15.3380\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3905 - val_loss: 15.3512\n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3917 - val_loss: 15.2286\n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3630 - val_loss: 15.2656\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3813 - val_loss: 15.3083\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3900 - val_loss: 15.3055\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3980 - val_loss: 15.2895\n",
      "Epoch 449/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3627 - val_loss: 15.3061\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3572 - val_loss: 15.3515\n",
      "Epoch 451/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3845 - val_loss: 15.2866\n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.4329 - val_loss: 15.3204\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4233 - val_loss: 15.3655\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3917 - val_loss: 15.4091\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3901 - val_loss: 15.3468\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3424 - val_loss: 15.3631\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3380 - val_loss: 15.3506\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3768 - val_loss: 15.3253\n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3649 - val_loss: 15.3283\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3334 - val_loss: 15.3060\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3415 - val_loss: 15.3976\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3463 - val_loss: 15.2891\n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3410 - val_loss: 15.3008\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3303 - val_loss: 15.4070\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3675 - val_loss: 15.4110\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3594 - val_loss: 15.3821\n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3315 - val_loss: 15.3438\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3329 - val_loss: 15.3183\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3501 - val_loss: 15.4087\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3435 - val_loss: 15.3585\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 15.3530\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3130 - val_loss: 15.3457\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3069 - val_loss: 15.3866\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3276 - val_loss: 15.3473\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3155 - val_loss: 15.3400\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3272 - val_loss: 15.3761\n",
      "Epoch 477/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3117 - val_loss: 15.3555\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3268 - val_loss: 15.3310\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3225 - val_loss: 15.4081\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3281 - val_loss: 15.4001\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2831 - val_loss: 15.4133\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3362 - val_loss: 15.3835\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2962 - val_loss: 15.3455\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3059 - val_loss: 15.3538\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3114 - val_loss: 15.4775\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3137 - val_loss: 15.4021\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 15.4453\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3235 - val_loss: 15.4912\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3210 - val_loss: 15.4467\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3084 - val_loss: 15.3813\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2930 - val_loss: 15.4285\n",
      "Epoch 492/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2917 - val_loss: 15.3786\n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3303 - val_loss: 15.4767\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3094 - val_loss: 15.4102\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2673 - val_loss: 15.3753\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2577 - val_loss: 15.4814\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3048 - val_loss: 15.4520\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2966 - val_loss: 15.4586\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2930 - val_loss: 15.4407\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2425 - val_loss: 15.5565\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3286 - val_loss: 15.4105\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2650 - val_loss: 15.4770\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2489 - val_loss: 15.3769\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2379 - val_loss: 15.5287\n",
      "Epoch 505/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2286 - val_loss: 15.4671\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2870 - val_loss: 15.4497\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2497 - val_loss: 15.4748\n",
      "Epoch 508/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2543 - val_loss: 15.4664\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2704 - val_loss: 15.4382\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3081 - val_loss: 15.3975\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2251 - val_loss: 15.4416\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2395 - val_loss: 15.5167\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2734 - val_loss: 15.5229\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2256 - val_loss: 15.4641\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2574 - val_loss: 15.4919\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2367 - val_loss: 15.4880\n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2249 - val_loss: 15.4746\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2487 - val_loss: 15.4218\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2041 - val_loss: 15.4463\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2030 - val_loss: 15.4564\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2012 - val_loss: 15.4620\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2460 - val_loss: 15.5627\n",
      "Epoch 523/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2402 - val_loss: 15.5506\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2347 - val_loss: 15.4726\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2342 - val_loss: 15.5210\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2146 - val_loss: 15.5086\n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2757 - val_loss: 15.4250\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2354 - val_loss: 15.5285\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2164 - val_loss: 15.5955\n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2038 - val_loss: 15.5353\n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2968 - val_loss: 15.4674\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1790 - val_loss: 15.5226\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1788 - val_loss: 15.4936\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1949 - val_loss: 15.6751\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2525 - val_loss: 15.4910\n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1777 - val_loss: 15.5368\n",
      "Epoch 537/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 15.6033\n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1522 - val_loss: 15.5498\n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1500 - val_loss: 15.5451\n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1475 - val_loss: 15.5721\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2059 - val_loss: 15.5664\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1966 - val_loss: 15.5615\n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2056 - val_loss: 15.6596\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 15.5495\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1640 - val_loss: 15.7087\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1697 - val_loss: 15.5889\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1700 - val_loss: 15.5927\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1306 - val_loss: 15.6348\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1563 - val_loss: 15.6532\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1869 - val_loss: 15.6291\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1872 - val_loss: 15.6480\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1452 - val_loss: 15.6281\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 15.6494\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1498 - val_loss: 15.6415\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1733 - val_loss: 15.6368\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1222 - val_loss: 15.7444\n",
      "Epoch 557/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1375 - val_loss: 15.6458\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1409 - val_loss: 15.6628\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1069 - val_loss: 15.6886\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1423 - val_loss: 15.7116\n",
      "Epoch 561/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 15.7045\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1332 - val_loss: 15.6487\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1212 - val_loss: 15.7217\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1373 - val_loss: 15.8220\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2004 - val_loss: 15.7424\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1337 - val_loss: 15.6813\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1310 - val_loss: 15.6534\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1104 - val_loss: 15.6909\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 15.6803\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1087 - val_loss: 15.6516\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1171 - val_loss: 15.6585\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1157 - val_loss: 15.6739\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 15.6532\n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1965 - val_loss: 15.6097\n",
      "Epoch 575/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1234 - val_loss: 15.6538\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1306 - val_loss: 15.6497\n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1984 - val_loss: 15.6075\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1215 - val_loss: 15.6528\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1006 - val_loss: 15.6739\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1476 - val_loss: 15.6642\n",
      "Epoch 581/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1464 - val_loss: 15.6539\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1261 - val_loss: 15.7370\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1245 - val_loss: 15.6331\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1506 - val_loss: 15.6801\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1378 - val_loss: 15.6431\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 15.6665\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1254 - val_loss: 15.7097\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1482 - val_loss: 15.7073\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1415 - val_loss: 15.6811\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1141 - val_loss: 15.6608\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1136 - val_loss: 15.6777\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1094 - val_loss: 15.6136\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1276 - val_loss: 15.6193\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1436 - val_loss: 15.7305\n",
      "Epoch 595/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1244 - val_loss: 15.6704\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 15.7258\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1107 - val_loss: 15.6709\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1218 - val_loss: 15.7173\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 15.6571\n",
      "Epoch 600/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1127 - val_loss: 15.7993\n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1089 - val_loss: 15.6365\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 15.6550\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1065 - val_loss: 15.6736\n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1284 - val_loss: 15.6624\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1434 - val_loss: 15.7196\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1331 - val_loss: 15.6815\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1795 - val_loss: 15.7013\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1618 - val_loss: 15.7754\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1120 - val_loss: 15.6737\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1257 - val_loss: 15.6492\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 15.6602\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1183 - val_loss: 15.7009\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1569 - val_loss: 15.6888\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1581 - val_loss: 15.6578\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1256 - val_loss: 15.7092\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1199 - val_loss: 15.6635\n",
      "Epoch 617/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1292 - val_loss: 15.6925\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1501 - val_loss: 15.6837\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 15.6926\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1198 - val_loss: 15.6820\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1255 - val_loss: 15.7216\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1503 - val_loss: 15.6557\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1590 - val_loss: 15.6630\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1345 - val_loss: 15.6703\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1414 - val_loss: 15.7369\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 15.6372\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1203 - val_loss: 15.6795\n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1301 - val_loss: 15.6870\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 15.6646\n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1115 - val_loss: 15.6597\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1250 - val_loss: 15.7067\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1661 - val_loss: 15.6865\n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1181 - val_loss: 15.6799\n",
      "Epoch 634/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1289 - val_loss: 15.6672\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1206 - val_loss: 15.6633\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1115 - val_loss: 15.6776\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1297 - val_loss: 15.6580\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1216 - val_loss: 15.7053\n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1414 - val_loss: 15.6795\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 15.6565\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 15.6885\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1059 - val_loss: 15.7024\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 15.6434\n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1334 - val_loss: 15.7549\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1505 - val_loss: 15.7340\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1317 - val_loss: 15.6422\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1143 - val_loss: 15.6629\n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1186 - val_loss: 15.6585\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1635 - val_loss: 15.6741\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1375 - val_loss: 15.7352\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1584 - val_loss: 15.7037\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1111 - val_loss: 15.7148\n",
      "Epoch 653/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1045 - val_loss: 15.6788\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1078 - val_loss: 15.7396\n",
      "Epoch 655/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1289 - val_loss: 15.6547\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 15.6736\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1286 - val_loss: 15.6658\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1346 - val_loss: 15.6552\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1489 - val_loss: 15.7842\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1280 - val_loss: 15.7173\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 15.7798\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1480 - val_loss: 15.6657\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1204 - val_loss: 15.6462\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 15.7057\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1048 - val_loss: 15.6576\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1147 - val_loss: 15.7084\n",
      "Epoch 667/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1110 - val_loss: 15.7098\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 15.6795\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1281 - val_loss: 15.7082\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1573 - val_loss: 15.6802\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1199 - val_loss: 15.6808\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1116 - val_loss: 15.7184\n",
      "Epoch 673/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1834 - val_loss: 15.5940\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1546 - val_loss: 15.6512\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1073 - val_loss: 15.6798\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 15.7025\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1578 - val_loss: 15.6723\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1275 - val_loss: 15.7009\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1113 - val_loss: 15.6979\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1649 - val_loss: 15.7414\n",
      "Epoch 681/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1311 - val_loss: 15.6849\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1162 - val_loss: 15.6916\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0981 - val_loss: 15.6865\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 15.6521\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1236 - val_loss: 15.7281\n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1253 - val_loss: 15.6541\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1074 - val_loss: 15.6786\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1414 - val_loss: 15.6816\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1149 - val_loss: 15.6844\n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1370 - val_loss: 15.7043\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1243 - val_loss: 15.6442\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1176 - val_loss: 15.7638\n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1336 - val_loss: 15.6711\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 15.6733\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 15.6573\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1250 - val_loss: 15.6666\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 15.8348\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1452 - val_loss: 15.6370\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1289 - val_loss: 15.6728\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1215 - val_loss: 15.6424\n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1232 - val_loss: 15.6620\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 15.6234\n",
      "Epoch 703/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1377 - val_loss: 15.6571\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1272 - val_loss: 15.6505\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1637 - val_loss: 15.7620\n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1634 - val_loss: 15.7458\n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1183 - val_loss: 15.6400\n",
      "Epoch 708/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1257 - val_loss: 15.6775\n",
      "Epoch 709/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1256 - val_loss: 15.6477\n",
      "Epoch 710/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1390 - val_loss: 15.7480\n",
      "Epoch 711/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1341 - val_loss: 15.6579\n",
      "Epoch 712/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1278 - val_loss: 15.6558\n",
      "Epoch 713/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1275 - val_loss: 15.7472\n",
      "Epoch 714/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 15.6895\n",
      "Epoch 715/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 15.7755\n",
      "Epoch 716/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1247 - val_loss: 15.6663\n",
      "Epoch 717/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1132 - val_loss: 15.6910\n",
      "Epoch 718/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1391 - val_loss: 15.6691\n",
      "Epoch 719/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1373 - val_loss: 15.7020\n",
      "Epoch 720/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1591 - val_loss: 15.6276\n",
      "Epoch 721/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1147 - val_loss: 15.7189\n",
      "Epoch 722/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1281 - val_loss: 15.6721\n",
      "Epoch 723/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1188 - val_loss: 15.7004\n",
      "Epoch 724/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 15.7125\n",
      "Epoch 725/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1163 - val_loss: 15.6538\n",
      "Epoch 726/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1448 - val_loss: 15.6671\n",
      "Epoch 727/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1284 - val_loss: 15.6696\n",
      "Epoch 728/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1361 - val_loss: 15.6676\n",
      "Epoch 729/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1462 - val_loss: 15.6730\n",
      "Epoch 730/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1019 - val_loss: 15.6709\n",
      "Epoch 731/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1520 - val_loss: 15.6945\n",
      "Epoch 732/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 15.6535\n",
      "Epoch 733/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1075 - val_loss: 15.6664\n",
      "Epoch 734/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1140 - val_loss: 15.7138\n",
      "Epoch 735/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1332 - val_loss: 15.6652\n",
      "Epoch 736/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 15.6401\n",
      "Epoch 737/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1704 - val_loss: 15.6701\n",
      "Epoch 738/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1222 - val_loss: 15.6599\n",
      "Epoch 739/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1056 - val_loss: 15.6662\n",
      "Epoch 740/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1071 - val_loss: 15.7062\n",
      "Epoch 741/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 15.6696\n",
      "Epoch 742/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 15.7694\n",
      "Epoch 743/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1729 - val_loss: 15.6698\n",
      "Epoch 744/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1223 - val_loss: 15.6844\n",
      "Epoch 745/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1170 - val_loss: 15.6624\n",
      "Epoch 746/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1297 - val_loss: 15.7260\n",
      "Epoch 747/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1608 - val_loss: 15.6299\n",
      "Epoch 748/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1287 - val_loss: 15.6741\n",
      "Epoch 749/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1220 - val_loss: 15.7368\n",
      "Epoch 750/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 15.7243\n",
      "Epoch 751/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1236 - val_loss: 15.6453\n",
      "Epoch 752/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1221 - val_loss: 15.7051\n",
      "Epoch 753/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 15.6778\n",
      "Epoch 754/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1281 - val_loss: 15.8453\n",
      "Epoch 755/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1415 - val_loss: 15.7118\n",
      "Epoch 756/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1368 - val_loss: 15.6784\n",
      "Epoch 757/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1288 - val_loss: 15.6812\n",
      "Epoch 758/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1298 - val_loss: 15.6414\n",
      "Epoch 759/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1178 - val_loss: 15.6757\n",
      "Epoch 760/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1196 - val_loss: 15.6667\n",
      "Epoch 761/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 15.6523\n",
      "Epoch 762/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1214 - val_loss: 15.7102\n",
      "Epoch 763/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1321 - val_loss: 15.6572\n",
      "Epoch 764/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1184 - val_loss: 15.6550\n",
      "Epoch 765/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1252 - val_loss: 15.6544\n",
      "Epoch 766/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1140 - val_loss: 15.6697\n",
      "Epoch 767/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1191 - val_loss: 15.6345\n",
      "Epoch 768/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1394 - val_loss: 15.6891\n",
      "Epoch 769/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1289 - val_loss: 15.6590\n",
      "Epoch 770/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1252 - val_loss: 15.6991\n",
      "Epoch 771/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1168 - val_loss: 15.7058\n",
      "Epoch 772/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1284 - val_loss: 15.6026\n",
      "Epoch 773/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1567 - val_loss: 15.6718\n",
      "Epoch 774/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1124 - val_loss: 15.7292\n",
      "Epoch 775/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 15.6415\n",
      "Epoch 776/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 15.7418\n",
      "Epoch 777/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1253 - val_loss: 15.6619\n",
      "Epoch 778/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1261 - val_loss: 15.6869\n",
      "Epoch 779/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1427 - val_loss: 15.7015\n",
      "Epoch 780/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1152 - val_loss: 15.6150\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1243 - val_loss: 15.6896\n",
      "Epoch 782/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1474 - val_loss: 15.7317\n",
      "Epoch 783/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1503 - val_loss: 15.6249\n",
      "Epoch 784/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 15.6480\n",
      "Epoch 785/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1133 - val_loss: 15.6905\n",
      "Epoch 786/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 15.6513\n",
      "Epoch 787/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1213 - val_loss: 15.7454\n",
      "Epoch 788/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1194 - val_loss: 15.6838\n",
      "Epoch 789/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1113 - val_loss: 15.6793\n",
      "Epoch 790/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1135 - val_loss: 15.7983\n",
      "Epoch 791/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1227 - val_loss: 15.6755\n",
      "Epoch 792/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1261 - val_loss: 15.6668\n",
      "Epoch 793/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1340 - val_loss: 15.7384\n",
      "Epoch 794/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1217 - val_loss: 15.6825\n",
      "Epoch 795/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1313 - val_loss: 15.6789\n",
      "Epoch 796/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1291 - val_loss: 15.7392\n",
      "Epoch 797/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1305 - val_loss: 15.6223\n",
      "Epoch 798/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1560 - val_loss: 15.7313\n",
      "Epoch 799/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 15.6595\n",
      "Epoch 800/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1113 - val_loss: 15.7528\n",
      "Epoch 801/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1269 - val_loss: 15.6679\n",
      "Epoch 802/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1168 - val_loss: 15.7686\n",
      "Epoch 803/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 15.6969\n",
      "Epoch 804/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1068 - val_loss: 15.6710\n",
      "Epoch 805/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 15.6761\n",
      "Epoch 806/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1223 - val_loss: 15.6665\n",
      "Epoch 807/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1420 - val_loss: 15.6563\n",
      "Epoch 808/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0970 - val_loss: 15.6861\n",
      "Epoch 809/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1092 - val_loss: 15.7243\n",
      "Epoch 810/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1157 - val_loss: 15.6798\n",
      "Epoch 811/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1312 - val_loss: 15.6880\n",
      "Epoch 812/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1188 - val_loss: 15.6778\n",
      "Epoch 813/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1248 - val_loss: 15.6783\n",
      "Epoch 814/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1140 - val_loss: 15.6728\n",
      "Epoch 815/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1172 - val_loss: 15.6976\n",
      "Epoch 816/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1088 - val_loss: 15.6739\n",
      "Epoch 817/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1359 - val_loss: 15.6402\n",
      "Epoch 818/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1220 - val_loss: 15.6921\n",
      "Epoch 819/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1599 - val_loss: 15.6277\n",
      "Epoch 820/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1414 - val_loss: 15.7008\n",
      "Epoch 821/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1224 - val_loss: 15.6553\n",
      "Epoch 822/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1308 - val_loss: 15.7022\n",
      "Epoch 823/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1442 - val_loss: 15.7287\n",
      "Epoch 824/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1073 - val_loss: 15.6764\n",
      "Epoch 825/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1148 - val_loss: 15.7218\n",
      "Epoch 826/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1277 - val_loss: 15.6742\n",
      "Epoch 827/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1041 - val_loss: 15.6606\n",
      "Epoch 828/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1335 - val_loss: 15.7458\n",
      "Epoch 829/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1455 - val_loss: 15.6804\n",
      "Epoch 830/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1161 - val_loss: 15.6603\n",
      "Epoch 831/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1105 - val_loss: 15.6789\n",
      "Epoch 832/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1233 - val_loss: 15.6534\n",
      "Epoch 833/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1316 - val_loss: 15.7156\n",
      "Epoch 834/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1544 - val_loss: 15.6840\n",
      "Epoch 835/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 15.6850\n",
      "Epoch 836/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1346 - val_loss: 15.6474\n",
      "Epoch 837/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1268 - val_loss: 15.7447\n",
      "Epoch 838/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1406 - val_loss: 15.6407\n",
      "Epoch 839/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2002 - val_loss: 15.7976\n",
      "Epoch 840/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2025 - val_loss: 15.6661\n",
      "Epoch 841/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1958 - val_loss: 15.7944\n",
      "Epoch 842/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1014 - val_loss: 15.6781\n",
      "Epoch 843/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0925 - val_loss: 15.7028\n",
      "Epoch 844/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1295 - val_loss: 15.6588\n",
      "Epoch 845/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1294 - val_loss: 15.6964\n",
      "Epoch 846/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1409 - val_loss: 15.7352\n",
      "Epoch 847/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1005 - val_loss: 15.6816\n",
      "Epoch 848/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1253 - val_loss: 15.6907\n",
      "Epoch 849/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1484 - val_loss: 15.6343\n",
      "Epoch 850/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1638 - val_loss: 15.6582\n",
      "Epoch 851/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1406 - val_loss: 15.6886\n",
      "Epoch 852/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1594 - val_loss: 15.6883\n",
      "Epoch 853/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1223 - val_loss: 15.7383\n",
      "Epoch 854/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1472 - val_loss: 15.7824\n",
      "Epoch 855/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1307 - val_loss: 15.7337\n",
      "Epoch 856/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1152 - val_loss: 15.7306\n",
      "Epoch 857/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1387 - val_loss: 15.7064\n",
      "Epoch 858/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - val_loss: 15.7174\n",
      "Epoch 859/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1261 - val_loss: 15.6593\n",
      "Epoch 860/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1552 - val_loss: 15.7925\n",
      "Epoch 861/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1400 - val_loss: 15.6156\n",
      "Epoch 862/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1161 - val_loss: 15.6684\n",
      "Epoch 863/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1321 - val_loss: 15.6607\n",
      "Epoch 864/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 15.7669\n",
      "Epoch 865/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1292 - val_loss: 15.7172\n",
      "Epoch 866/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1566 - val_loss: 15.6872\n",
      "Epoch 867/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1188 - val_loss: 15.6748\n",
      "Epoch 868/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1140 - val_loss: 15.7373\n",
      "Epoch 869/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1227 - val_loss: 15.6699\n",
      "Epoch 870/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 15.7323\n",
      "Epoch 871/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 15.7183\n",
      "Epoch 872/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1855 - val_loss: 15.6356\n",
      "Epoch 873/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1297 - val_loss: 15.6708\n",
      "Epoch 874/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1296 - val_loss: 15.6474\n",
      "Epoch 875/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1402 - val_loss: 15.6703\n",
      "Epoch 876/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1050 - val_loss: 15.6744\n",
      "Epoch 877/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1223 - val_loss: 15.6607\n",
      "Epoch 878/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1413 - val_loss: 15.7442\n",
      "Epoch 879/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 15.6624\n",
      "Epoch 880/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1699 - val_loss: 15.6580\n",
      "Epoch 881/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1563 - val_loss: 15.6742\n",
      "Epoch 882/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1132 - val_loss: 15.6642\n",
      "Epoch 883/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1369 - val_loss: 15.7600\n",
      "Epoch 884/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1374 - val_loss: 15.6885\n",
      "Epoch 885/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 15.6687\n",
      "Epoch 886/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1420 - val_loss: 15.6608\n",
      "Epoch 887/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1526 - val_loss: 15.6681\n",
      "Epoch 888/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1422 - val_loss: 15.6662\n",
      "Epoch 889/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1417 - val_loss: 15.8098\n",
      "Epoch 890/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1430 - val_loss: 15.6866\n",
      "Epoch 891/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 15.6584\n",
      "Epoch 892/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 15.6853\n",
      "Epoch 893/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1158 - val_loss: 15.6542\n",
      "Epoch 894/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1005 - val_loss: 15.7542\n",
      "Epoch 895/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0984 - val_loss: 15.7224\n",
      "Epoch 896/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1262 - val_loss: 15.6652\n",
      "Epoch 897/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1145 - val_loss: 15.7109\n",
      "Epoch 898/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1448 - val_loss: 15.6855\n",
      "Epoch 899/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1113 - val_loss: 15.6865\n",
      "Epoch 900/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 15.6739\n",
      "Epoch 901/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 15.6854\n",
      "Epoch 902/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1138 - val_loss: 15.6646\n",
      "Epoch 903/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0995 - val_loss: 15.6344\n",
      "Epoch 904/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1247 - val_loss: 15.6779\n",
      "Epoch 905/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1560 - val_loss: 15.7898\n",
      "Epoch 906/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1390 - val_loss: 15.7022\n",
      "Epoch 907/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1509 - val_loss: 15.7254\n",
      "Epoch 908/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1342 - val_loss: 15.7328\n",
      "Epoch 909/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1324 - val_loss: 15.6860\n",
      "Epoch 910/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1461 - val_loss: 15.7250\n",
      "Epoch 911/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1527 - val_loss: 15.6610\n",
      "Epoch 912/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1196 - val_loss: 15.7645\n",
      "Epoch 913/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1367 - val_loss: 15.6558\n",
      "Epoch 914/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1504 - val_loss: 15.7052\n",
      "Epoch 915/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 15.6752\n",
      "Epoch 916/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1494 - val_loss: 15.6401\n",
      "Epoch 917/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1253 - val_loss: 15.6690\n",
      "Epoch 918/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1227 - val_loss: 15.7269\n",
      "Epoch 919/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1225 - val_loss: 15.6923\n",
      "Epoch 920/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1293 - val_loss: 15.6740\n",
      "Epoch 921/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1091 - val_loss: 15.7666\n",
      "Epoch 922/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1737 - val_loss: 15.7753\n",
      "Epoch 923/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1263 - val_loss: 15.6829\n",
      "Epoch 924/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1129 - val_loss: 15.7446\n",
      "Epoch 925/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1672 - val_loss: 15.7555\n",
      "Epoch 926/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1569 - val_loss: 15.6778\n",
      "Epoch 927/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1281 - val_loss: 15.7084\n",
      "Epoch 928/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1068 - val_loss: 15.6397\n",
      "Epoch 929/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1835 - val_loss: 15.6821\n",
      "Epoch 930/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1547 - val_loss: 15.6909\n",
      "Epoch 931/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1296 - val_loss: 15.6612\n",
      "Epoch 932/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1164 - val_loss: 15.6830\n",
      "Epoch 933/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1084 - val_loss: 15.7122\n",
      "Epoch 934/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1146 - val_loss: 15.7084\n",
      "Epoch 935/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1081 - val_loss: 15.6866\n",
      "Epoch 936/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1204 - val_loss: 15.7618\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1283 - val_loss: 15.6845\n",
      "Epoch 938/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1163 - val_loss: 15.6911\n",
      "Epoch 939/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0953 - val_loss: 15.7018\n",
      "Epoch 940/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1586 - val_loss: 15.6312\n",
      "Epoch 941/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1366 - val_loss: 15.7196\n",
      "Epoch 942/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1303 - val_loss: 15.7320\n",
      "Epoch 943/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1102 - val_loss: 15.7434\n",
      "Epoch 944/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1628 - val_loss: 15.6342\n",
      "Epoch 945/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1358 - val_loss: 15.7394\n",
      "Epoch 946/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1625 - val_loss: 15.6286\n",
      "Epoch 947/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1495 - val_loss: 15.7328\n",
      "Epoch 948/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1293 - val_loss: 15.6937\n",
      "Epoch 949/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1025 - val_loss: 15.6861\n",
      "Epoch 950/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1161 - val_loss: 15.6862\n",
      "Epoch 951/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1171 - val_loss: 15.6944\n",
      "Epoch 952/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1390 - val_loss: 15.6773\n",
      "Epoch 953/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1697 - val_loss: 15.7143\n",
      "Epoch 954/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1482 - val_loss: 15.6694\n",
      "Epoch 955/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1501 - val_loss: 15.6944\n",
      "Epoch 956/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1040 - val_loss: 15.6784\n",
      "Epoch 957/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0994 - val_loss: 15.6608\n",
      "Epoch 958/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1887 - val_loss: 15.6679\n",
      "Epoch 959/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1083 - val_loss: 15.6838\n",
      "Epoch 960/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1617 - val_loss: 15.6850\n",
      "Epoch 961/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 15.6667\n",
      "Epoch 962/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0924 - val_loss: 15.6928\n",
      "Epoch 963/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1780 - val_loss: 15.7103\n",
      "Epoch 964/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1294 - val_loss: 15.6681\n",
      "Epoch 965/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 15.6773\n",
      "Epoch 966/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1033 - val_loss: 15.6433\n",
      "Epoch 967/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1394 - val_loss: 15.8138\n",
      "Epoch 968/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1656 - val_loss: 15.6344\n",
      "Epoch 969/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1538 - val_loss: 15.6883\n",
      "Epoch 970/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1761 - val_loss: 15.6827\n",
      "Epoch 971/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1307 - val_loss: 15.6680\n",
      "Epoch 972/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1396 - val_loss: 15.6490\n",
      "Epoch 973/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1595 - val_loss: 15.6828\n",
      "Epoch 974/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1587 - val_loss: 15.6888\n",
      "Epoch 975/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1345 - val_loss: 15.6817\n",
      "Epoch 976/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1123 - val_loss: 15.6801\n",
      "Epoch 977/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1197 - val_loss: 15.6949\n",
      "Epoch 978/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1243 - val_loss: 15.7197\n",
      "Epoch 979/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1059 - val_loss: 15.7254\n",
      "Epoch 980/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1259 - val_loss: 15.6802\n",
      "Epoch 981/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1392 - val_loss: 15.6566\n",
      "Epoch 982/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1418 - val_loss: 15.6878\n",
      "Epoch 983/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1370 - val_loss: 15.7327\n",
      "Epoch 984/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1101 - val_loss: 15.6927\n",
      "Epoch 985/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1315 - val_loss: 15.6834\n",
      "Epoch 986/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1382 - val_loss: 15.7240\n",
      "Epoch 987/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1326 - val_loss: 15.6782\n",
      "Epoch 988/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1204 - val_loss: 15.7324\n",
      "Epoch 989/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1551 - val_loss: 15.6838\n",
      "Epoch 990/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1082 - val_loss: 15.6751\n",
      "Epoch 991/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1053 - val_loss: 15.7951\n",
      "Epoch 992/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1174 - val_loss: 15.6761\n",
      "Epoch 993/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1319 - val_loss: 15.6474\n",
      "Epoch 994/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 15.6777\n",
      "Epoch 995/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1079 - val_loss: 15.6612\n",
      "Epoch 996/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0978 - val_loss: 15.6596\n",
      "Epoch 997/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1556 - val_loss: 15.7352\n",
      "Epoch 998/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1551 - val_loss: 15.7097\n",
      "Epoch 999/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1631 - val_loss: 15.7559\n",
      "Epoch 1000/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1562 - val_loss: 15.6641\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHrVJREFUeJzt3X2wXHWd5/H395zue28SHvLMhgQnscwwiA8BLhiWZVdEkKArWAqlyJpyU8aqZXadBxxhttRia//Aqi1BqkacKMzEJ5QFGRiMCkZYa6cETZTFSHASHIZcgiQ8JEIe7u2H7/5xfn3v6b59czs33bdv//J5VXX1Ob/z63N+p0/yOb/769Onzd0REZF4Jd1ugIiIdJaCXkQkcgp6EZHIKehFRCKnoBcRiZyCXkQkcgp6EZHIKehFRCKnoBcRiVyh2w0AWLhwoS9fvrzbzRAR6Slbt259yd0XTVZvRgT98uXL2bJlS7ebISLSU8zsX1upp6EbEZHIKehFRCKnoBcRidyMGKMXEZmKUqnE0NAQhw8f7nZTOmpgYIBly5ZRLBan9HoFvYj0rKGhIU488USWL1+OmXW7OR3h7rz88ssMDQ2xYsWKKa1DQzci0rMOHz7MggULog15ADNjwYIFx/RXi4JeRHpazCFfc6z72NNBv+XZV7j5B0+jn0MUEZlYTwf9tqF93Pt/trLnteFuN0VEjkP79u3jy1/+8lG/7vLLL2ffvn0daFFzPR30F7/0DR7vv47fDu3tdlNE5Dg0UdBXKpUjvm7Tpk3MnTu3U80ap6eD/qRT30Rizr7n/7nbTRGR49ANN9zAM888w6pVqzj33HO56KKLuOaaa3jrW98KwJVXXsk555zDmWeeyYYNG0Zft3z5cl566SWeffZZzjjjDD7xiU9w5plncumll3Lo0KG2t7OnL688ccnpAFRe2glc3N3GiEhX3fSPv+Gp3X9o6zrffOpJfP4/njnh8ptvvplt27bxxBNP8Oijj/Le976Xbdu2jV4GeeeddzJ//nwOHTrEueeeywc/+EEWLFhQt44dO3Zw11138dWvfpWrr76ae++9l2uvvbat+9HTQZ+cfCoA5f2/73JLRETgvPPOq7vW/bbbbuO+++4DYNeuXezYsWNc0K9YsYJVq1YBcM455/Dss8+2vV09HfTMzt6w9NArXW6IiHTbkXre02XOnDmj048++ig//vGP+dnPfsbs2bN55zvf2fRa+P7+/tHpNE07MnTT02P0FPo5aLPpG1HQi8j0O/HEE3nttdeaLtu/fz/z5s1j9uzZPP300zz22GPT3Loxvd2jBw4U5jKrNH2XKYmI1CxYsIALLriAt7zlLcyaNYtTTjlldNlll13GV77yFd72trdx+umns3r16q61s+eD/lBxLnMOKuhFpDu+/e1vNy3v7+/nBz/4QdNltXH4hQsXsm3bttHy66+/vu3tg14fugFG+uZzUnW/vh0rIjKBng/68sB85tlrHBg58hcURESOVz0f9Myez3xeY9/BkW63RERkRmop6M1srpndY2ZPm9l2MzvfzOab2cNmtiM8zwt1zcxuM7OdZvakmZ3dyR1IB06i30rsP3Cwk5sREelZrfbovwT80N3/BHg7sB24Adjs7iuBzWEeYA2wMjzWA7e3tcUNCrNPAuDAfn0gKyLSzKRBb2YnAf8euAPA3UfcfR9wBbAxVNsIXBmmrwC+7pnHgLlmtqTtLQ+Ks7KgHz7Y3q8+i4jEopUe/RuBvcDfmdmvzOxrZjYHOMXdXwAIz4tD/aXArtzrh0JZR6Qh6EsH93dqEyIiTU31NsUAt956KwcPTs+QcytBXwDOBm5397OAA4wN0zTT7KdQxl37aGbrzWyLmW3Zu3fqtxnun5MFfeVw82+niYh0Sq8EfStfmBoChtz98TB/D1nQv2hmS9z9hTA0sydX/7Tc65cBuxtX6u4bgA0Ag4ODU74Ivm/2yQCUD2noRkSmV/42xZdccgmLFy/m7rvvZnh4mA984APcdNNNHDhwgKuvvpqhoSEqlQqf/exnefHFF9m9ezcXXXQRCxcu5JFHHuloOycNenf/vZntMrPT3f23ZPcDfio81gI3h+f7w0seAP7UzL4DvAPYXxvi6YT+OVnQu3r0Ise3H9wAv/91e9f5b94Ka26ecHH+NsUPPfQQ99xzDz//+c9xd97//vfz05/+lL1793Lqqafy/e9/H8jugXPyySfzxS9+kUceeYSFCxe2t81NtHoLhP8KfMvM+oDfAR8nG/a528zWAc8BV4W6m4DLgZ3AwVC3Y2ofxvqwgl5Euuehhx7ioYce4qyzzgLg9ddfZ8eOHVx44YVcf/31fOYzn+F973sfF1544bS3raWgd/cngMEmi8b92odn9yK47hjb1br+E7PnkdenbZMiMgMdoec9HdydG2+8kU9+8pPjlm3dupVNmzZx4403cumll/K5z31uWtvW+9+M7TsBgERBLyLTLH+b4ve85z3ceeedvP56lkXPP/88e/bsYffu3cyePZtrr72W66+/nl/+8pfjXttpPX/3Sgp9jFAkKR3odktE5DiTv03xmjVruOaaazj//PMBOOGEE/jmN7/Jzp07+fSnP02SJBSLRW6/PfsO6fr161mzZg1Llizp+IexNhPu+jg4OOhbtmyZ8uv/cNNp/GLOf+Di67/ZxlaJyEy3fft2zjjjjG43Y1o021cz2+ruzYbV6/T+0A0wkvRj5fE/0SUiIpEEfSkZIK0o6EVEmoki6MvJAIWqgl7keDQThp877Vj3MYqgr6T9FBX0IsedgYEBXn755ajD3t15+eWXGRgYmPI6ev+qG6CSDtDnugWCyPFm2bJlDA0NcSz3y+oFAwMDLFu2bMqvjyToZ9HvcR9oERmvWCyyYsWKbjdjxoti6KZamEW/D0f955uIyFRFEfRemMWAjTBcrna7KSIiM040QT+LEQ6XKt1uiojIjBNF0FOcxSyGOVxSj15EpFEUQW/FWQxYicMjpW43RURkxokj6PtmAzB8WDc2ExFpFEnQzwJg5JCCXkSkURRBn/TNAaCkHr2IyDhRBH3anw3dlA/rx0dERBrFEfRh6KY0rPvdiIg0iiLoi/1Z0FdKCnoRkUZxBH1fdle38sihLrdERGTmiSPoB0KPfkQ9ehGRRi0FvZk9a2a/NrMnzGxLKJtvZg+b2Y7wPC+Um5ndZmY7zexJMzu7kzsA0NevoBcRmcjR9OgvcvdVuR+ivQHY7O4rgc1hHmANsDI81gO3t6uxE6kFvZeHO70pEZGecyxDN1cAG8P0RuDKXPnXPfMYMNfMlhzDdiZVCGP0rh8IFxEZp9Wgd+AhM9tqZutD2Snu/gJAeF4cypcCu3KvHQpldcxsvZltMbMtx/zrMIXwE1vq0YuIjNPqL0xd4O67zWwx8LCZPX2EutakbNwvgrj7BmADwODg4LH9Ykjanz0r6EVExmmpR+/uu8PzHuA+4DzgxdqQTHjeE6oPAaflXr4M2N2uBjdVUNCLiExk0qA3szlmdmJtGrgU2AY8AKwN1dYC94fpB4CPhatvVgP7a0M8HROC3ioKehGRRq0M3ZwC3GdmtfrfdvcfmtkvgLvNbB3wHHBVqL8JuBzYCRwEPt72VjdKClRIFPQiIk1MGvTu/jvg7U3KXwYublLuwHVtaV2rzChRIKmMTOtmRUR6QRTfjAUoWR9JVT16EZFG0QR92YokVfXoRUQaRRP0Jesj1dCNiMg40QR92fpI1aMXERknmqCvJAp6EZFmIgr6Iqkr6EVEGkUU9P0UFfQiIuPEE/TWR8FL3W6GiMiME03QV9M+9ehFRJqIKOj7KapHLyIyTkRB30cRBb2ISKNogt7TfvooUa0e263tRURiE1XQ91NipFLtdlNERGaUaIKeQtajHy4r6EVE8qIK+n5KjCjoRUTqRBP0lvZTsCojJV1iKSKSF03Q135OsDR8uMsNERGZWaIJeisOAFAaPtTlloiIzCzRBH0SevRlBb2ISJ14gr7YB0C5rJ8TFBHJiyfoa2P0Iwp6EZG8loPezFIz+5WZPRjmV5jZ42a2w8y+a2Z9obw/zO8My5d3pun10lqPXlfdiIjUOZoe/aeA7bn5LwC3uPtK4FVgXShfB7zq7m8Cbgn1Oi4NH8ZW1KMXEanTUtCb2TLgvcDXwrwB7wLuCVU2AleG6SvCPGH5xaF+RxUKRQAqGqMXEanTao/+VuCvgNrXThcA+9y9HOaHgKVheimwCyAs3x/qd1Tal43RVzR0IyJSZ9KgN7P3AXvcfWu+uElVb2FZfr3rzWyLmW3Zu3dvS409kkIxC/pqST16EZG8Vnr0FwDvN7Nnge+QDdncCsw1s0KoswzYHaaHgNMAwvKTgVcaV+ruG9x90N0HFy1adEw7Abmgr6hHLyKSN2nQu/uN7r7M3ZcDHwZ+4u4fBR4BPhSqrQXuD9MPhHnC8p+4e8dvEl8IV91Uy/rxERGRvGO5jv4zwF+Y2U6yMfg7QvkdwIJQ/hfADcfWxNakfdlVN6hHLyJSpzB5lTHu/ijwaJj+HXBekzqHgava0LajUuvRe1lBLyKSF803Y2tj9Ap6EZF60QR97RYIVBX0IiJ50QQ9aTZ0Q0UfxoqI5EUU9Nk3Y/VhrIhIvYiCPuvRm4JeRKROREFf69Fr6EZEJC+eoE9SyiRYVUEvIpIXT9ADZQqYevQiInWiCvoKBRJdXikiUieqoC9bQUM3IiINIgv6ooJeRKRBVEFfsQKpgl5EpE5UQV+miI3+6JWIiEBkQV9J1KMXEWkUV9BbkcQV9CIieVEFfdWKpBq6ERGpE1XQV5ICqXr0IiJ1ogr6aqIevYhIo7iC3ooU1KMXEakTVdB7UqSgHr2ISJ2ogr6a9FFAQS8ikjdp0JvZgJn93Mz+n5n9xsxuCuUrzOxxM9thZt81s75Q3h/md4blyzu7C2M8VY9eRKRRKz36YeBd7v52YBVwmZmtBr4A3OLuK4FXgXWh/jrgVXd/E3BLqDctPClSRGP0IiJ5kwa9Z14Ps8XwcOBdwD2hfCNwZZi+IswTll9sZta2Fh9JUqRAGXefls2JiPSClsbozSw1syeAPcDDwDPAPvfRcZIhYGmYXgrsAgjL9wML2tnoiXhapI8ypYqCXkSkpqWgd/eKu68ClgHnAWc0qxaem/XexyWvma03sy1mtmXv3r2ttvfI0j6KVChXq+1Zn4hIBI7qqht33wc8CqwG5ppZISxaBuwO00PAaQBh+cnAK03WtcHdB919cNGiRVNrfeM60yJFypTK6tGLiNS0ctXNIjObG6ZnAe8GtgOPAB8K1dYC94fpB8I8YflPfJoGzS3to2gVRsq68kZEpKYweRWWABvNLCU7Mdzt7g+a2VPAd8zsfwK/Au4I9e8AvmFmO8l68h/uQLubsrQIQLk8Asyars2KiMxokwa9uz8JnNWk/Hdk4/WN5YeBq9rSuqNVC/oRXWIpIlIT1Tdjx3r0w11uiYjIzBFV0Cdp9gdKuTTS5ZaIiMwckQV9HwDlkoZuRERqogp6K+Q/jBUREYgs6JMQ9BUN3YiIjIor6MPQTbWsoRsRkZq4gl5DNyIi40QV9Gkh69Fr6EZEZExUQV/r0VcrGroREamJLOhrY/Tq0YuI1EQV9Gno0bs+jBURGRVX0BdDj15DNyIio+IK+nALhGpFtykWEamJK+hDj941Ri8iMiquoA8fxrqGbkRERkUV9IXRoNfQjYhITVRBXxu6oaKhGxGRmqiCvlAMl1dq6EZEZFRUQW/hpmZe1dCNiEhNVEFPkvXoUY9eRGRUXEEfrqNX0IuIjIkr6Gs9+qqCXkSkZtKgN7PTzOwRM9tuZr8xs0+F8vlm9rCZ7QjP80K5mdltZrbTzJ40s7M7vROjktCjr1ambZMiIjNdKz36MvCX7n4GsBq4zszeDNwAbHb3lcDmMA+wBlgZHuuB29ve6omkGqMXEWk0adC7+wvu/ssw/RqwHVgKXAFsDNU2AleG6SuAr3vmMWCumS1pe8ubMaNMgrmuuhERqTmqMXozWw6cBTwOnOLuL0B2MgAWh2pLgV25lw2FssZ1rTezLWa2Ze/evUff8glUKGAaoxcRGdVy0JvZCcC9wJ+5+x+OVLVJmY8rcN/g7oPuPrho0aJWmzGpMimmWyCIiIxqKejNrEgW8t9y9++F4hdrQzLheU8oHwJOy718GbC7Pc2dXMUKGroREclp5aobA+4Atrv7F3OLHgDWhum1wP258o+Fq29WA/trQzzTQUM3IiL1Ci3UuQD4T8CvzeyJUPbXwM3A3Wa2DngOuCos2wRcDuwEDgIfb2uLJ1GxlES3QBARGTVp0Lv7/6X5uDvAxU3qO3DdMbZryipWINHQjYjIqLi+GQtUNUYvIlInwqBP1aMXEcmJMOgLJLoFgojIqDiDXj16EZFR8QV9oqAXEcmLL+itQKqgFxEZFV3Qe1IgRUEvIlITXdBXragevYhITnRB70mB1HXVjYhITZxBr6EbEZFRUQZ9AfXoRURqogt6kgIFL5PdckdERKILek+KpFalXFXQi4hAhEFPUqBIhXJFQS8iAlEGfZECZUrVardbIiIyI8QX9Gn2Yax69CIimfiCPimGoRv16EVEIMagT4sUqFDSh7EiIkCkQV+0CqWSrqUXEYEIg97SIgDl8kiXWyIiMjNEF/RJLehLpS63RERkZpg06M3sTjPbY2bbcmXzzexhM9sRnueFcjOz28xsp5k9aWZnd7LxTYWgr6hHLyICtNaj/3vgsoayG4DN7r4S2BzmAdYAK8NjPXB7e5rZOksLAJTL6tGLiEALQe/uPwVeaSi+AtgYpjcCV+bKv+6Zx4C5ZrakXY1tRZL2AVBV0IuIAFMfoz/F3V8ACM+LQ/lSYFeu3lAomzZWCEM3peHp3KyIyIzV7g9jrUlZ0wvazWy9mW0xsy179+5tWwNqH8ZWKurRi4jA1IP+xdqQTHjeE8qHgNNy9ZYBu5utwN03uPuguw8uWrRois0YLwk9+mpJH8aKiMDUg/4BYG2YXgvcnyv/WLj6ZjWwvzbEM11qQV/RGL2ICACFySqY2V3AO4GFZjYEfB64GbjbzNYBzwFXheqbgMuBncBB4OMdaPMRJYXwYWxFPXoREWgh6N39IxMsurhJXQeuO9ZGHYvaGL2uuhERyUT3zdi01qPXF6ZERIAogz706CvlLrdERGRmiDDosx69K+hFRIAogz772EFX3YiIZKIL+kKx1qNX0IuIQIRBXxuj96qCXkQEIgz6gsboRUTqRBf0tW/GusboRUSACIOeJAXAq+rRi4hAlEGf9ejRh7EiIkCUQR/u6qAevYgIEGPQp7WrbhT0IiIQY9CHMXoN3YiIZCIM+jBGX610tx0iIjNEhEGvMXoRkbz4gj6t9egV9CIiEGPQW7ZLplsgiIgALfzCVM8x46DN4uL998Hdr8HJp8HsBXDSqTBnIcyaB3MWZ/O1D25FRCIWX9ADXz3hv/DukR9z5otPwY6HoXRwfCVLoDgH+uZA3+zsuW7+hFBWm56gTnE2FGdlQ0ZJEdK+bDrtyx5JfH80iUhviTLo/+mES/gnLuHuT54P7lA6BPuH4NCrcOgVeO332fzIASgdyJ5HDsLI63B4H/zh+bH50kEoH556YyzNBX/uudlJIS02qXuk+oWG19ZOLoXsUS2DV6BaDc8VqJbAq9n7kn/Gaw3O6qTZzeGoVrLlSZrtyyjPTXp7ytu5rgnLmaC8oR1T2Ubt/a2UAAvDiJ6r27gNA7Ox5R6Ok1ezR9rX8J4fiY9to3Zca2VmY8fTq2Pbbdxns7A9r19mlr0Gsv2re/0k+1e3jlyZ5/5NJmn279XS0L7cNi3JvS+ezVuS/dvOt2vcdjqhQ+s+80p4w+rOrDuIMuj70oSDI+HDWLOs973oj6e+wko5C/yRA81PDpWR3KOUey7Vl1dLDXVGsnXXpsvDMPxaC3WH2/NGSRvk/vMnaTjRFqkLy3zI1Sad8XVqIZak2XN5uMkJqBkfW7cljJ1AcoFcKYVtG/WBnGuQkwVq/vX5EwiMXdXmPra+uv3Lnbjq2pcvqwV2mu1rtRw6FN7k/amOvS9mYyexJHdSqH9RZ3Rw1ZxyZm8GvZldBnwJSIGvufvNndjORAqpUa628cikBUhPgoGT2rfOY+Gh91gZGetBNp5oquWxnv1ogDTM5/8D5Xt4SZqdVGrltV5VNYRAzUS9p7ryieofaT1H+5oOlDcu62hPUaSz2h70ZpYCfwNcAgwBvzCzB9z9qXZvayKFJOHVgyPsOzhCXyGhmCYUEqNSdRIzkqTH/9OahZNPlH+QiUibdSIpzgN2uvvvAMzsO8AVwLQF/Qn9KbteOcSq//FwXbkZpGbM7ksppuEEkBp94Tmbz04KaWINz6E8NRIzDEgM0iQhTSBNsvJCkp1IUsteW3skDfOp1eplry1XnWKa0F9IRusniZEY2bRZ2F72+r40IUnGby8xo5DmtmdGkoCF1xtj+1RIDQv7Unt/DDti57VWpzYN5F5fv65amYh0VyeCfimwKzc/BLyjA9uZ0F+/9wzOXTGf4VKVUiV7jFScatWpuHNopDJaXq44papTKlcpV7N6lWqVStUpVaocKjmV6tijXM3WU3Wn6owt87H1VyrhOdQrV721odbItXRiyI1jN1t2pHXkX1c7wTTWp+F1lntxvq6TG8kKJ9j8NsftU6ttnEDdiHaTfyyj65hotGyS9U+V/tkeWeMnHjC+YNzH/A3H988v+WOuWLW0zS2r14mgb/Zvbtx7YWbrgfUAb3jDG9ragMUnDvDRd/xRW9d5rNzzJwQoV6tUq4yeEAqJUapUGS5X604iHqarnj/ZVCnlTly1k0/txFKprT9MV6uOk51sqp5tsxxOch4OjftYuNXqNnbG8/8+a/9Ya2VeN12/znxFz83m6020DuqWtbbNcW0cdyzG9rFxPdTtu42up1L1cXWP2Ma6bTVu35v+pVP3aUGT9746QW+haanTtvTv1t9kbdyFjmj2kfbofMMBHL98bHrBnP52NqupTgT9EHBabn4ZsLuxkrtvADYADA4ORt9xsDCkMvaG68taIjI9OvFtnl8AK81shZn1AR8GHujAdkREpAVt79G7e9nM/hT4EVm39U53/027tyMiIq3pyPV57r4J2NSJdYuIyNHRjVhERCKnoBcRiZyCXkQkcgp6EZHIKehFRCJnzb5uPe2NMNsL/OsUX74QeKmNzekF2ufjg/b5+HAs+/xH7r5oskozIuiPhZltcffBbrdjOmmfjw/a5+PDdOyzhm5ERCKnoBcRiVwMQb+h2w3oAu3z8UH7fHzo+D73/Bi9iIgcWQw9ehEROYKeDnozu8zMfmtmO83shm63p13M7DQze8TMtpvZb8zsU6F8vpk9bGY7wvO8UG5mdlt4H540s7O7uwdTY2apmf3KzB4M8yvM7PGwv98Nt73GzPrD/M6wfHk32z1VZjbXzO4xs6fDsT7/ODjGfx7+TW8zs7vMbCDG42xmd5rZHjPblis76mNrZmtD/R1mtnaq7enZoM/9CPka4M3AR8zszd1tVduUgb909zOA1cB1Yd9uADa7+0pgc5iH7D1YGR7rgdunv8lt8Slge27+C8AtYX9fBdaF8nXAq+7+JuCWUK8XfQn4obv/CfB2sn2P9hib2VLgvwGD7v4WstuYf5g4j/PfA5c1lB3VsTWz+cDnyX6K9Tzg87WTw1Fz9558AOcDP8rN3wjc2O12dWhf7wcuAX4LLAllS4Dfhum/BT6Sqz9ar1ceZL9Ethl4F/Ag2a+vvQQUGo832W8dnB+mC6GedXsfjnJ/TwL+pbHdkR/j2u9Jzw/H7UHgPbEeZ2A5sG2qxxb4CPC3ufK6ekfz6NkePc1/hLyzv7DbBeHP1bOAx4FT3P0FgPC8OFSL4b24FfgroBrmFwD73L0c5vP7NLq/Yfn+UL+XvBHYC/xdGK76mpnNIeJj7O7PA/8LeA54gey4bSXu45x3tMe2bce8l4O+pR8h72VmdgJwL/Bn7v6HI1VtUtYz74WZvQ/Y4+5b88VNqnoLy3pFATgbuN3dzwIOMPanfDM9v89h2OEKYAVwKjCHbNiiUUzHuRUT7Wfb9r+Xg76lHyHvVWZWJAv5b7n790Lxi2a2JCxfAuwJ5b3+XlwAvN/MngW+QzZ8cysw18xqv4KW36fR/Q3LTwZemc4Gt8EQMOTuj4f5e8iCP9ZjDPBu4F/cfa+7l4DvAf+WuI9z3tEe27Yd814O+mh/hNzMDLgD2O7uX8wtegCoffK+lmzsvlb+sfDp/Wpgf+1PxF7g7je6+zJ3X052HH/i7h8FHgE+FKo17m/tffhQqN9TPT13/z2wy8xOD0UXA08R6TEOngNWm9ns8G+8ts/RHucGR3tsfwRcambzwl9Dl4ayo9ftDyyO8cOOy4F/Bp4B/nu329PG/fp3ZH+iPQk8ER6Xk41PbgZ2hOf5ob6RXYH0DPBrsqsaur4fU9z3dwIPhuk3Aj8HdgL/G+gP5QNhfmdY/sZut3uK+7oK2BKO8z8A82I/xsBNwNPANuAbQH+Mxxm4i+xziBJZz3zdVI4t8J/D/u8EPj7V9uibsSIikevloRsREWmBgl5EJHIKehGRyCnoRUQip6AXEYmcgl5EJHIKehGRyCnoRUQi9/8BWTALCK+H+dUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=1000, batch_size=1, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 38.554\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_steps*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -7:]), axis=1)\n",
    "#inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -7:]), axis=1)\n",
    "#inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [650.0438 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8789 ],\n",
       "       [617.8274 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8789 ],\n",
       "       [653.8379 ],\n",
       "       [653.8789 ],\n",
       "       [653.8789 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.61084],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.607  ],\n",
       "       [653.8379 ],\n",
       "       [678.0996 ],\n",
       "       [651.4869 ],\n",
       "       [521.65326],\n",
       "       [655.77496],\n",
       "       [652.1636 ],\n",
       "       [667.5432 ],\n",
       "       [611.8241 ],\n",
       "       [647.1648 ],\n",
       "       [653.8668 ],\n",
       "       [633.9208 ],\n",
       "       [512.37463],\n",
       "       [658.16675],\n",
       "       [512.4882 ],\n",
       "       [661.3104 ],\n",
       "       [523.2638 ],\n",
       "       [662.6598 ],\n",
       "       [646.9057 ],\n",
       "       [665.02454],\n",
       "       [651.0405 ],\n",
       "       [515.6503 ],\n",
       "       [658.6992 ],\n",
       "       [657.0263 ],\n",
       "       [661.3104 ],\n",
       "       [653.87616],\n",
       "       [666.9259 ],\n",
       "       [495.97165],\n",
       "       [657.42456],\n",
       "       [652.01306],\n",
       "       [503.43225],\n",
       "       [646.0484 ],\n",
       "       [660.1169 ],\n",
       "       [626.776  ],\n",
       "       [653.8789 ],\n",
       "       [659.24255],\n",
       "       [661.2694 ],\n",
       "       [653.8789 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8789 ],\n",
       "       [589.4921 ],\n",
       "       [653.8378 ],\n",
       "       [653.8379 ],\n",
       "       [647.56177],\n",
       "       [653.8379 ],\n",
       "       [653.8789 ],\n",
       "       [685.81213],\n",
       "       [653.8379 ],\n",
       "       [653.8789 ],\n",
       "       [653.8789 ],\n",
       "       [647.5873 ],\n",
       "       [653.8379 ],\n",
       "       [653.8444 ],\n",
       "       [653.8789 ],\n",
       "       [653.88696],\n",
       "       [653.8379 ],\n",
       "       [655.1904 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [651.4015 ],\n",
       "       [654.8    ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [683.042  ],\n",
       "       [653.8379 ],\n",
       "       [653.8378 ],\n",
       "       [689.89   ],\n",
       "       [653.8379 ],\n",
       "       [650.0091 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8384 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8782 ],\n",
       "       [653.8378 ],\n",
       "       [653.84314],\n",
       "       [640.06854],\n",
       "       [653.8378 ],\n",
       "       [654.3699 ],\n",
       "       [653.8752 ],\n",
       "       [653.8378 ],\n",
       "       [653.87555],\n",
       "       [653.8378 ],\n",
       "       [653.8789 ],\n",
       "       [617.8274 ],\n",
       "       [653.8378 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8379 ],\n",
       "       [653.8789 ],\n",
       "       [504.32483],\n",
       "       [656.8862 ],\n",
       "       [653.113  ],\n",
       "       [525.8218 ]], dtype=float32)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 78 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-305-00a088e867ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m78\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m78\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m78\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 78 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "plt.plot(train_X[:,78], train_y, 'b')\n",
    "\n",
    "plt.plot(test_X[:,78], test_y, 'g')\n",
    "plt.plot(test_X[:,78], yhat, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[290.       ,   1.8      , 654.       , ..., 233.1301   ,\n",
       "           0.       ,   0.       ],\n",
       "        [  6.       ,   6.       , 290.       , ...,   0.       ,\n",
       "           0.       , 240.94539  ],\n",
       "        [  0.       ,   0.       ,   6.       , ...,   0.9041371,\n",
       "           8.174638 , 270.       ],\n",
       "        [270.       , 246.0375   ,   7.       , ...,   8.126746 ,\n",
       "           0.       ,   0.       ],\n",
       "        [  8.126746 ,   0.       ,  90.       , ...,   0.       ,\n",
       "           0.       ,   0.       ]],\n",
       "\n",
       "       [[290.       ,   1.8      , 654.       , ..., 240.94539  ,\n",
       "           0.       ,   0.       ],\n",
       "        [  6.       ,   4.       , 289.9      , ..., 270.       ,\n",
       "         270.       , 246.0375   ],\n",
       "        [  7.       ,   7.       ,   6.       , ...,   0.       ,\n",
       "           8.126746 ,   0.       ],\n",
       "        [ 90.       , 246.0375   ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       ,   0.       ,   0.       , ...,   0.       ,\n",
       "          -0.8895634,   0.       ]],\n",
       "\n",
       "       [[289.9      ,   1.8      , 654.       , ..., 246.0375   ,\n",
       "           7.       ,   7.       ],\n",
       "        [  6.       ,   4.       , 289.9      , ...,   0.       ,\n",
       "          90.       , 246.0375   ],\n",
       "        [  0.       ,   3.       ,   6.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       , 246.0375   ,   0.       , ...,   0.       ,\n",
       "          -7.91323  ,   0.8895634],\n",
       "        [  7.91323  , 180.       , 180.       , ...,   0.       ,\n",
       "           0.       ,   0.       ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[289.9      ,   1.8      , 653.9      , ..., 135.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  4.       ,   2.       , 289.9      , ...,   0.       ,\n",
       "           0.       , 126.869896 ],\n",
       "        [  0.       ,   0.       ,   3.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       , 119.0546   ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       ,   0.       ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ]],\n",
       "\n",
       "       [[289.9      ,   1.8      , 653.9      , ..., 126.869896 ,\n",
       "           0.       ,   0.       ],\n",
       "        [  3.       ,   3.       , 289.9      , ...,   0.       ,\n",
       "           0.       , 119.0546   ],\n",
       "        [  0.       ,   0.       ,   3.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       , 113.96249  ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       ,   0.       ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ]],\n",
       "\n",
       "       [[289.9      ,   1.8      , 653.9      , ..., 119.0546   ,\n",
       "           0.       ,   0.       ],\n",
       "        [  3.       ,   3.       , 289.9      , ...,   0.       ,\n",
       "           0.       , 113.96249  ],\n",
       "        [  0.       ,   0.       ,   3.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       , 113.96249  ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ],\n",
       "        [  0.       ,   0.       ,   0.       , ...,   0.       ,\n",
       "           0.       ,   0.       ]]], dtype=float32)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
